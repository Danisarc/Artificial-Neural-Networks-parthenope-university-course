{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "x0uJW5xqqqlm"
      },
      "source": [
        "### Solving Median House Value classification problem implementing a **deep neural network with tanh** and tf.Keras\n",
        "This experiment shows that a feed-forward deep artificial neural network (at least three hidden layers) with enough hidden neurons, and activation functions that saturate (*tanh*) does not train properly. Any neuron in the third hidden layer receives 10,000 inputs from the previous layer. Therefore, the *net* likely gets very high (in absolute value). The derivative of the *tanh* for a high *net* is close to zero, which makes delta and weights update also close to zero. Going back to the previous layer, there is nothing left to update the weights since the learning algorithm multiplies the derivative of the *tanh* for a high *net* (nearly zero) by the delta values previously calculated, also close to zero. As the algorithm approaches lower layers, the gradient error gets diluted even more, not updating at all their weights. This effect results in small changes in the weigts at the top layers and no changes at all near the input. Different layers learn at different speeds so the final trained neural network converges to a poor local optimum.     \n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Tensorflow and tf.keras\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "\n",
        "#Helper libraries\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "from tqdm import tqdm\n",
        "\n",
        "# Google file system\n",
        "from google.colab import drive\n",
        "drive.mount('/gdrive', force_remount=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 108
        },
        "colab_type": "code",
        "id": "-SAQX4N2qqls",
        "outputId": "1fbf5f6e-7939-46d6-ff63-fc58b670584c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "x_train: (16342, 9)\n",
            "t_train: (16342, 3)\n",
            "x_dev: (2043, 9)\n",
            "t_dev: (2043, 3)\n"
          ]
        }
      ],
      "source": [
        "ATT_FILE = \"/gdrive/My Drive/Colab Notebooks/datasets/Housing/MedianHouseValue/MedianHouseValuePreparedCleanAttributes.csv\"\n",
        "LABEL_FILE = \"/gdrive/My Drive/Colab Notebooks/datasets/Housing/MedianHouseValue/MedianHouseValueOneHotEncodedClasses.csv\"\n",
        "\n",
        "TRAIN_RATE=0.8\n",
        "\n",
        "attributes = pd.read_csv(ATT_FILE)\n",
        "label = pd.read_csv(LABEL_FILE)\n",
        "\n",
        "n_instances = attributes.shape[0]\n",
        "n_train = int(n_instances*TRAIN_RATE)\n",
        "n_dev = int((n_instances-n_train)/2)\n",
        "\n",
        "x_train = attributes.values[:n_train]\n",
        "t_train = label.values[:n_train]\n",
        "\n",
        "x_dev = attributes.values[n_train:n_train+n_dev]\n",
        "t_dev = label.values[n_train:n_train+n_dev]\n",
        "\n",
        "print (\"x_train:\",x_train.shape)\n",
        "print (\"t_train:\",t_train.shape)\n",
        "\n",
        "print (\"x_dev:\",x_dev.shape)\n",
        "print (\"t_dev:\",t_dev.shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "dawlzBekqql1"
      },
      "source": [
        "## Initialization"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "kdnGXfsNqql2"
      },
      "outputs": [],
      "source": [
        "INPUTS = x_train.shape[1]\n",
        "OUTPUTS = t_train.shape[1]\n",
        "NUM_TRAINING_EXAMPLES = int(round(x_train.shape[0]/1))\n",
        "NUM_DEV_EXAMPLES = int (round (x_dev.shape[0]/1))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "_Vg7Bfaqqql5"
      },
      "source": [
        "Some data is displayed to test correctness:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 213
        },
        "colab_type": "code",
        "id": "7iy9Yc1mqqmE",
        "outputId": "8c6bd9e0-abbc-484e-dbe0-6ac823621155"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([[ 0.21713147, -0.69394261,  0.41176471, -0.93926446, -0.88733706,\n",
              "        -0.90924634, -0.89278079, -0.77585137, -1.        ],\n",
              "       [-0.69322709,  0.17747078, -0.29411765, -0.91795107, -0.88671633,\n",
              "        -0.95448303, -0.88949186, -0.59159184,  1.        ],\n",
              "       [ 0.44820717, -0.95961743,  0.37254902, -0.8306628 , -0.80074488,\n",
              "        -0.89349477, -0.79575728, -0.5589716 ,  1.        ],\n",
              "       [ 0.29083665, -0.7088204 , -0.41176471, -0.87629076, -0.85909373,\n",
              "        -0.94315984, -0.84377569, -0.48705535, -1.        ],\n",
              "       [-0.40039841,  0.15834219, -0.49019608, -0.8418536 , -0.84574798,\n",
              "        -0.93413493, -0.82765992, -0.16468738, -0.33333333]])"
            ]
          },
          "execution_count": 4,
          "metadata": {
            "tags": []
          },
          "output_type": "execute_result"
        }
      ],
      "source": [
        "x_train[:5]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 213
        },
        "colab_type": "code",
        "id": "DmdArrI0qqmG",
        "outputId": "213f9f59-d6c4-4335-f1c6-37dee0cd78ab"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([[1., 0., 0.],\n",
              "       [0., 0., 1.],\n",
              "       [1., 0., 0.],\n",
              "       [0., 1., 0.],\n",
              "       [0., 0., 1.],\n",
              "       [1., 0., 0.],\n",
              "       [1., 0., 0.],\n",
              "       [0., 0., 1.],\n",
              "       [0., 0., 1.],\n",
              "       [0., 0., 1.]])"
            ]
          },
          "execution_count": 5,
          "metadata": {
            "tags": []
          },
          "output_type": "execute_result"
        }
      ],
      "source": [
        "t_train[:10]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 213
        },
        "colab_type": "code",
        "id": "dJEJkVdpqqmH",
        "outputId": "1d47e579-9ecc-44f6-c702-7344c821a365"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([[ 0.22908367, -0.67906482,  0.45098039, -0.83366397, -0.77343265,\n",
              "        -0.81524146, -0.76155238, -0.67868029, -1.        ],\n",
              "       [-0.61752988,  0.10308183,  1.        , -0.94201129, -0.93078833,\n",
              "        -0.97247681, -0.93257688, -0.37100178,  0.33333333],\n",
              "       [-0.39043825,  0.16046759, -0.88235294, -0.92929447, -0.90037244,\n",
              "        -0.90016536, -0.89870087, -0.74136908, -0.33333333],\n",
              "       [-0.24701195, -0.45377258, -0.33333333, -0.85156926, -0.82774674,\n",
              "        -0.94030102, -0.81877981, -0.58286093, -1.        ],\n",
              "       [ 0.22908367, -0.73645058, -0.25490196, -0.90589552, -0.82774674,\n",
              "        -0.90420135, -0.81746423, -0.86805699,  1.        ]])"
            ]
          },
          "execution_count": 6,
          "metadata": {
            "tags": []
          },
          "output_type": "execute_result"
        }
      ],
      "source": [
        "x_dev[:5]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 125
        },
        "colab_type": "code",
        "id": "DTfWBp2aqqmJ",
        "outputId": "72405cf9-bd26-4b2a-cdc0-ae724c3038f3"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([[1., 0., 0.],\n",
              "       [0., 0., 1.],\n",
              "       [1., 0., 0.],\n",
              "       [0., 1., 0.],\n",
              "       [0., 1., 0.]])"
            ]
          },
          "execution_count": 7,
          "metadata": {
            "tags": []
          },
          "output_type": "execute_result"
        }
      ],
      "source": [
        "t_dev[:5]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "zzdGAahIqqmL"
      },
      "source": [
        "## Hyperparameters"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "bk2y7RR0qqmL"
      },
      "source": [
        "The number of hidden layers and neurons per layer must be adjusted. In this example, we try to increase the computational power of the neural network by adding up to three hidden layers (to be deep) and more neurons per layer. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "9llGmGvkqqmM"
      },
      "outputs": [],
      "source": [
        "n_epochs = 600 # corresponding to about 20,000 iterations\n",
        "learning_rate = 0.1\n",
        "batch_size = 500\n",
        "n_neurons_per_hlayer = [10000,10000, 10000] "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "Dl-AsL42qqmN"
      },
      "source": [
        "## Build the deep neural model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "ekeUf4K3H8TQ"
      },
      "source": [
        "First of all, a sequential model is created. This is the one of Keras models, for full-connected feedforward neural networks, in which layers are sequentially connected. This is called the *sequential* API."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "qOVJ3QSyImxj"
      },
      "outputs": [],
      "source": [
        "model = keras.Sequential(name=\"Feedforward NN\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "_YoyNRtuLubc"
      },
      "source": [
        "Define the deep neural network topology. Note that the **tanh** activation function is chosen for the hidden layers and  **softmax** for the ouput layer. **We expect that the neural network does not train properly since we are employing an activation function that saturates at its tails**. \n",
        "\n",
        "Adding layers to the model. The model takes as input matrix tensors with *INPUTS* columns and any number of rows. *InputLayer* creates a placeholder where the data is ready to feed the network. Then the hidden layers with *tanh* activation function are created. Finally, the output layer with the *softmax* activation function is added. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 372
        },
        "colab_type": "code",
        "id": "_HC6q86_IzO7",
        "outputId": "545bf238-97ec-4028-8c49-a5e396782cbc"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/resource_variable_ops.py:1630: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "If using Keras pass *_constraint arguments to layers.\n",
            "Model: \"Feedforward NN\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "dense (Dense)                (None, 10000)             100000    \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 10000)             100010000 \n",
            "_________________________________________________________________\n",
            "dense_2 (Dense)              (None, 10000)             100010000 \n",
            "_________________________________________________________________\n",
            "dense_3 (Dense)              (None, 3)                 30003     \n",
            "=================================================================\n",
            "Total params: 200,150,003\n",
            "Trainable params: 200,150,003\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "model.add(keras.layers.InputLayer(input_shape=(INPUTS,), batch_size=None))\n",
        "\n",
        "for neurons in n_neurons_per_hlayer:\n",
        "  model.add(keras.layers.Dense(neurons, activation=\"tanh\"))\n",
        "\n",
        "model.add(keras.layers.Dense(OUTPUTS, activation=\"softmax\"))\n",
        "model.summary()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "UHB1vBGXRmRe"
      },
      "source": [
        "Two hundred million parameters to adjust. For example, the kernel in the last layer comprises 30,003 parameters: 10,000 neurons in the previous layer by 3 neurons in the output layer plus the three biases, one for each output neuron. \n",
        "\n",
        "This experiment could not be conducted some time ago due to a lack of computational resources. The difficulties in training deep neural networks could only be devised from mathematical analysis.   "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 108
        },
        "colab_type": "code",
        "id": "yf9kooY8RLmO",
        "outputId": "5f3ff494-a5ad-443c-98ed-5f89b5f6b438"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[<tensorflow.python.keras.layers.core.Dense at 0x7ffa12293278>,\n",
              " <tensorflow.python.keras.layers.core.Dense at 0x7ffa12293710>,\n",
              " <tensorflow.python.keras.layers.core.Dense at 0x7ffa11a42fd0>,\n",
              " <tensorflow.python.keras.layers.core.Dense at 0x7ffa122e61d0>]"
            ]
          },
          "execution_count": 11,
          "metadata": {
            "tags": []
          },
          "output_type": "execute_result"
        }
      ],
      "source": [
        "model.layers"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 108
        },
        "colab_type": "code",
        "id": "md6YxH5iRTPj",
        "outputId": "12165717-d4bb-44b7-f9e7-b3d0bba56c03"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "dense\n",
            "dense_1\n",
            "dense_2\n",
            "dense_3\n"
          ]
        }
      ],
      "source": [
        "for l in model.layers: print (l.name)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "U0gULZpfScnW"
      },
      "source": [
        "All the parameters of a layer can bee accessed:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 55
        },
        "colab_type": "code",
        "id": "LzorJMMJSg1d",
        "outputId": "845982af-0ba4-40d2-df4c-2171ebd270d9"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(9, 10000)"
            ]
          },
          "execution_count": 13,
          "metadata": {
            "tags": []
          },
          "output_type": "execute_result"
        }
      ],
      "source": [
        "weights, biases = model.layers[0].get_weights()\n",
        "weights.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 55
        },
        "colab_type": "code",
        "id": "nG-cVDSiTHJl",
        "outputId": "13a58132-80d0-470f-a2b7-eb5bb242c558"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([0., 0., 0., ..., 0., 0., 0.], dtype=float32)"
            ]
          },
          "execution_count": 14,
          "metadata": {
            "tags": []
          },
          "output_type": "execute_result"
        }
      ],
      "source": [
        "biases"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 55
        },
        "colab_type": "code",
        "id": "7gu0SkqLTP6l",
        "outputId": "57b70e72-468f-4b9c-a87d-b0e167ac2f60"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(10000,)"
            ]
          },
          "execution_count": 15,
          "metadata": {
            "tags": []
          },
          "output_type": "execute_result"
        }
      ],
      "source": [
        "biases.shape"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "zeHjWFsrTg1j"
      },
      "source": [
        "# Compiling the model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "b2nH4ki3TlqB"
      },
      "source": [
        "Compiling the model means specifying the *loss* function (the $log-loss$,  $cross-entropy$, the sum of log-loss is a loss) and the *optimizer* (Gradient Descent) to use. Optionally, you can also specify a list of extra *metrics* (Accuracy) to compute during training and evaluation. In this case, "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "XisSOCL1UDh8"
      },
      "outputs": [],
      "source": [
        "model.compile(loss=tf.keras.losses.categorical_crossentropy,\n",
        "              optimizer=tf.keras.optimizers.SGD(lr=learning_rate),\n",
        "              metrics=[\"categorical_accuracy\"])\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "aeM5hW8qUXgC"
      },
      "source": [
        "There are several losses functions, optimizers and metrics. Full lists are available at: https://keras.io/losses/, https://keras.io/optimizers/ and https://keras.io/metrics/.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "oQZsDnk8bCa8"
      },
      "source": [
        "## Training and validating the model with M-BGD"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "Qxora106dX1a"
      },
      "source": [
        "Note that an **epoch** is an iteration over the entire training dataset provided."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "colab_type": "code",
        "id": "7xiouC6pbG0m",
        "outputId": "6a6fe1c0-2f8a-4930-b955-64e9e2b5a7e4"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train on 16342 samples, validate on 2043 samples\n",
            "Epoch 1/600\n",
            "16342/16342 [==============================] - 12s 741us/sample - loss: 0.9901 - categorical_accuracy: 0.5269 - val_loss: 1.1185 - val_categorical_accuracy: 0.3671\n",
            "Epoch 2/600\n",
            "16342/16342 [==============================] - 11s 700us/sample - loss: 0.8802 - categorical_accuracy: 0.5799 - val_loss: 0.7695 - val_categorical_accuracy: 0.6559\n",
            "Epoch 3/600\n",
            "16342/16342 [==============================] - 11s 701us/sample - loss: 0.8265 - categorical_accuracy: 0.6015 - val_loss: 0.8274 - val_categorical_accuracy: 0.5952\n",
            "Epoch 4/600\n",
            "16342/16342 [==============================] - 12s 706us/sample - loss: 0.8156 - categorical_accuracy: 0.6102 - val_loss: 0.7248 - val_categorical_accuracy: 0.6735\n",
            "Epoch 5/600\n",
            "16342/16342 [==============================] - 11s 700us/sample - loss: 0.7693 - categorical_accuracy: 0.6425 - val_loss: 0.7251 - val_categorical_accuracy: 0.6691\n",
            "Epoch 6/600\n",
            "16342/16342 [==============================] - 12s 705us/sample - loss: 0.7470 - categorical_accuracy: 0.6559 - val_loss: 0.7042 - val_categorical_accuracy: 0.6853\n",
            "Epoch 7/600\n",
            "16342/16342 [==============================] - 11s 701us/sample - loss: 0.7317 - categorical_accuracy: 0.6646 - val_loss: 0.6636 - val_categorical_accuracy: 0.6907\n",
            "Epoch 8/600\n",
            "16342/16342 [==============================] - 11s 704us/sample - loss: 0.7437 - categorical_accuracy: 0.6565 - val_loss: 0.6829 - val_categorical_accuracy: 0.6848\n",
            "Epoch 9/600\n",
            "16342/16342 [==============================] - 11s 701us/sample - loss: 0.7018 - categorical_accuracy: 0.6802 - val_loss: 0.6623 - val_categorical_accuracy: 0.6887\n",
            "Epoch 10/600\n",
            "16342/16342 [==============================] - 11s 702us/sample - loss: 0.7184 - categorical_accuracy: 0.6718 - val_loss: 0.6575 - val_categorical_accuracy: 0.7073\n",
            "Epoch 11/600\n",
            "16342/16342 [==============================] - 11s 702us/sample - loss: 0.7170 - categorical_accuracy: 0.6743 - val_loss: 0.7031 - val_categorical_accuracy: 0.6735\n",
            "Epoch 12/600\n",
            "16342/16342 [==============================] - 11s 700us/sample - loss: 0.7116 - categorical_accuracy: 0.6794 - val_loss: 0.6530 - val_categorical_accuracy: 0.7024\n",
            "Epoch 13/600\n",
            "16342/16342 [==============================] - 11s 702us/sample - loss: 0.6969 - categorical_accuracy: 0.6888 - val_loss: 0.6559 - val_categorical_accuracy: 0.6975\n",
            "Epoch 14/600\n",
            "16342/16342 [==============================] - 11s 702us/sample - loss: 0.7170 - categorical_accuracy: 0.6724 - val_loss: 0.6898 - val_categorical_accuracy: 0.6823\n",
            "Epoch 15/600\n",
            "16342/16342 [==============================] - 11s 699us/sample - loss: 0.6874 - categorical_accuracy: 0.6939 - val_loss: 0.6492 - val_categorical_accuracy: 0.7058\n",
            "Epoch 16/600\n",
            "16342/16342 [==============================] - 11s 702us/sample - loss: 0.6882 - categorical_accuracy: 0.6959 - val_loss: 0.6490 - val_categorical_accuracy: 0.7068\n",
            "Epoch 17/600\n",
            "16342/16342 [==============================] - 11s 701us/sample - loss: 0.7087 - categorical_accuracy: 0.6780 - val_loss: 0.6499 - val_categorical_accuracy: 0.7058\n",
            "Epoch 18/600\n",
            "16342/16342 [==============================] - 11s 700us/sample - loss: 0.6980 - categorical_accuracy: 0.6867 - val_loss: 0.6493 - val_categorical_accuracy: 0.7048\n",
            "Epoch 19/600\n",
            "16342/16342 [==============================] - 11s 700us/sample - loss: 0.6780 - categorical_accuracy: 0.6972 - val_loss: 0.6462 - val_categorical_accuracy: 0.7102\n",
            "Epoch 20/600\n",
            "16342/16342 [==============================] - 11s 702us/sample - loss: 0.6974 - categorical_accuracy: 0.6875 - val_loss: 0.6502 - val_categorical_accuracy: 0.7068\n",
            "Epoch 21/600\n",
            "16342/16342 [==============================] - 11s 701us/sample - loss: 0.6974 - categorical_accuracy: 0.6879 - val_loss: 0.6677 - val_categorical_accuracy: 0.6897\n",
            "Epoch 22/600\n",
            "16342/16342 [==============================] - 11s 700us/sample - loss: 0.6878 - categorical_accuracy: 0.6925 - val_loss: 0.6521 - val_categorical_accuracy: 0.7039\n",
            "Epoch 23/600\n",
            "16342/16342 [==============================] - 11s 702us/sample - loss: 0.6782 - categorical_accuracy: 0.6979 - val_loss: 0.6454 - val_categorical_accuracy: 0.7068\n",
            "Epoch 24/600\n",
            "16342/16342 [==============================] - 11s 700us/sample - loss: 0.6828 - categorical_accuracy: 0.6968 - val_loss: 0.6772 - val_categorical_accuracy: 0.6941\n",
            "Epoch 25/600\n",
            "16342/16342 [==============================] - 11s 702us/sample - loss: 0.6839 - categorical_accuracy: 0.6967 - val_loss: 0.6512 - val_categorical_accuracy: 0.7137\n",
            "Epoch 26/600\n",
            "16342/16342 [==============================] - 11s 702us/sample - loss: 0.6828 - categorical_accuracy: 0.6943 - val_loss: 0.6492 - val_categorical_accuracy: 0.7039\n",
            "Epoch 27/600\n",
            "16342/16342 [==============================] - 11s 701us/sample - loss: 0.6881 - categorical_accuracy: 0.6941 - val_loss: 0.6459 - val_categorical_accuracy: 0.7024\n",
            "Epoch 28/600\n",
            "16342/16342 [==============================] - 12s 704us/sample - loss: 0.6830 - categorical_accuracy: 0.6952 - val_loss: 0.6772 - val_categorical_accuracy: 0.6970\n",
            "Epoch 29/600\n",
            "16342/16342 [==============================] - 11s 701us/sample - loss: 0.6780 - categorical_accuracy: 0.6990 - val_loss: 0.6431 - val_categorical_accuracy: 0.7141\n",
            "Epoch 30/600\n",
            "16342/16342 [==============================] - 11s 699us/sample - loss: 0.6872 - categorical_accuracy: 0.6951 - val_loss: 0.6435 - val_categorical_accuracy: 0.7083\n",
            "Epoch 31/600\n",
            "16342/16342 [==============================] - 11s 698us/sample - loss: 0.6854 - categorical_accuracy: 0.6926 - val_loss: 0.6453 - val_categorical_accuracy: 0.7117\n",
            "Epoch 32/600\n",
            "16342/16342 [==============================] - 11s 700us/sample - loss: 0.6848 - categorical_accuracy: 0.6958 - val_loss: 0.6448 - val_categorical_accuracy: 0.7190\n",
            "Epoch 33/600\n",
            "16342/16342 [==============================] - 11s 702us/sample - loss: 0.6745 - categorical_accuracy: 0.7019 - val_loss: 0.6607 - val_categorical_accuracy: 0.6970\n",
            "Epoch 34/600\n",
            "16342/16342 [==============================] - 11s 700us/sample - loss: 0.6766 - categorical_accuracy: 0.6998 - val_loss: 0.6498 - val_categorical_accuracy: 0.7156\n",
            "Epoch 35/600\n",
            "16342/16342 [==============================] - 11s 701us/sample - loss: 0.6986 - categorical_accuracy: 0.6883 - val_loss: 0.6705 - val_categorical_accuracy: 0.6941\n",
            "Epoch 36/600\n",
            "16342/16342 [==============================] - 12s 706us/sample - loss: 0.6762 - categorical_accuracy: 0.7013 - val_loss: 0.6502 - val_categorical_accuracy: 0.7004\n",
            "Epoch 37/600\n",
            "16342/16342 [==============================] - 12s 705us/sample - loss: 0.6849 - categorical_accuracy: 0.6942 - val_loss: 0.6498 - val_categorical_accuracy: 0.7181\n",
            "Epoch 38/600\n",
            "16342/16342 [==============================] - 11s 702us/sample - loss: 0.6817 - categorical_accuracy: 0.6965 - val_loss: 0.6471 - val_categorical_accuracy: 0.7034\n",
            "Epoch 39/600\n",
            "16342/16342 [==============================] - 12s 706us/sample - loss: 0.6809 - categorical_accuracy: 0.6979 - val_loss: 0.6461 - val_categorical_accuracy: 0.7166\n",
            "Epoch 40/600\n",
            "16342/16342 [==============================] - 12s 706us/sample - loss: 0.6794 - categorical_accuracy: 0.6981 - val_loss: 0.6595 - val_categorical_accuracy: 0.7073\n",
            "Epoch 41/600\n",
            "16342/16342 [==============================] - 11s 703us/sample - loss: 0.6877 - categorical_accuracy: 0.6983 - val_loss: 0.6461 - val_categorical_accuracy: 0.7093\n",
            "Epoch 42/600\n",
            "16342/16342 [==============================] - 12s 705us/sample - loss: 0.6838 - categorical_accuracy: 0.6943 - val_loss: 0.6448 - val_categorical_accuracy: 0.7073\n",
            "Epoch 43/600\n",
            "16342/16342 [==============================] - 12s 706us/sample - loss: 0.6755 - categorical_accuracy: 0.7018 - val_loss: 0.6414 - val_categorical_accuracy: 0.7166\n",
            "Epoch 44/600\n",
            "16342/16342 [==============================] - 11s 703us/sample - loss: 0.6796 - categorical_accuracy: 0.6985 - val_loss: 0.6440 - val_categorical_accuracy: 0.7044\n",
            "Epoch 45/600\n",
            "16342/16342 [==============================] - 12s 705us/sample - loss: 0.6732 - categorical_accuracy: 0.7000 - val_loss: 0.6522 - val_categorical_accuracy: 0.7156\n",
            "Epoch 46/600\n",
            "16342/16342 [==============================] - 12s 706us/sample - loss: 0.6807 - categorical_accuracy: 0.7006 - val_loss: 0.6745 - val_categorical_accuracy: 0.6975\n",
            "Epoch 47/600\n",
            "16342/16342 [==============================] - 11s 701us/sample - loss: 0.6724 - categorical_accuracy: 0.7021 - val_loss: 0.6539 - val_categorical_accuracy: 0.7063\n",
            "Epoch 48/600\n",
            "16342/16342 [==============================] - 12s 704us/sample - loss: 0.6714 - categorical_accuracy: 0.7039 - val_loss: 0.6497 - val_categorical_accuracy: 0.7102\n",
            "Epoch 49/600\n",
            "16342/16342 [==============================] - 11s 700us/sample - loss: 0.6726 - categorical_accuracy: 0.7041 - val_loss: 0.6455 - val_categorical_accuracy: 0.7210\n",
            "Epoch 50/600\n",
            "16342/16342 [==============================] - 11s 699us/sample - loss: 0.6757 - categorical_accuracy: 0.6985 - val_loss: 0.6394 - val_categorical_accuracy: 0.7146\n",
            "Epoch 51/600\n",
            "16342/16342 [==============================] - 11s 703us/sample - loss: 0.6720 - categorical_accuracy: 0.7033 - val_loss: 0.6462 - val_categorical_accuracy: 0.7009\n",
            "Epoch 52/600\n",
            "16342/16342 [==============================] - 11s 700us/sample - loss: 0.6765 - categorical_accuracy: 0.7001 - val_loss: 0.6550 - val_categorical_accuracy: 0.6946\n",
            "Epoch 53/600\n",
            "16342/16342 [==============================] - 11s 698us/sample - loss: 0.6906 - categorical_accuracy: 0.6898 - val_loss: 0.7136 - val_categorical_accuracy: 0.6657\n",
            "Epoch 54/600\n",
            "16342/16342 [==============================] - 11s 697us/sample - loss: 0.6741 - categorical_accuracy: 0.7026 - val_loss: 0.6386 - val_categorical_accuracy: 0.7146\n",
            "Epoch 55/600\n",
            "16342/16342 [==============================] - 11s 697us/sample - loss: 0.6723 - categorical_accuracy: 0.7046 - val_loss: 0.6393 - val_categorical_accuracy: 0.7137\n",
            "Epoch 56/600\n",
            "16342/16342 [==============================] - 11s 700us/sample - loss: 0.6736 - categorical_accuracy: 0.7040 - val_loss: 0.6370 - val_categorical_accuracy: 0.7156\n",
            "Epoch 57/600\n",
            "16342/16342 [==============================] - 11s 703us/sample - loss: 0.6771 - categorical_accuracy: 0.6978 - val_loss: 0.6515 - val_categorical_accuracy: 0.7141\n",
            "Epoch 58/600\n",
            "16342/16342 [==============================] - 11s 701us/sample - loss: 0.6661 - categorical_accuracy: 0.7081 - val_loss: 0.6393 - val_categorical_accuracy: 0.7117\n",
            "Epoch 59/600\n",
            "16342/16342 [==============================] - 11s 700us/sample - loss: 0.6813 - categorical_accuracy: 0.7002 - val_loss: 0.7026 - val_categorical_accuracy: 0.6818\n",
            "Epoch 60/600\n",
            "16342/16342 [==============================] - 11s 698us/sample - loss: 0.6743 - categorical_accuracy: 0.7018 - val_loss: 0.6858 - val_categorical_accuracy: 0.6853\n",
            "Epoch 61/600\n",
            "16342/16342 [==============================] - 11s 698us/sample - loss: 0.6723 - categorical_accuracy: 0.7070 - val_loss: 0.6647 - val_categorical_accuracy: 0.6882\n",
            "Epoch 62/600\n",
            "16342/16342 [==============================] - 11s 697us/sample - loss: 0.6756 - categorical_accuracy: 0.7005 - val_loss: 0.6402 - val_categorical_accuracy: 0.7088\n",
            "Epoch 63/600\n",
            "16342/16342 [==============================] - 11s 698us/sample - loss: 0.6692 - categorical_accuracy: 0.7043 - val_loss: 0.7241 - val_categorical_accuracy: 0.6667\n",
            "Epoch 64/600\n",
            "16342/16342 [==============================] - 11s 698us/sample - loss: 0.6794 - categorical_accuracy: 0.6994 - val_loss: 0.6939 - val_categorical_accuracy: 0.6769\n",
            "Epoch 65/600\n",
            "16342/16342 [==============================] - 11s 701us/sample - loss: 0.6669 - categorical_accuracy: 0.7060 - val_loss: 0.6366 - val_categorical_accuracy: 0.7210\n",
            "Epoch 66/600\n",
            "16342/16342 [==============================] - 11s 701us/sample - loss: 0.6654 - categorical_accuracy: 0.7081 - val_loss: 0.6393 - val_categorical_accuracy: 0.7088\n",
            "Epoch 67/600\n",
            "16342/16342 [==============================] - 11s 698us/sample - loss: 0.6828 - categorical_accuracy: 0.6975 - val_loss: 0.6397 - val_categorical_accuracy: 0.7205\n",
            "Epoch 68/600\n",
            "16342/16342 [==============================] - 11s 699us/sample - loss: 0.6710 - categorical_accuracy: 0.7043 - val_loss: 0.6694 - val_categorical_accuracy: 0.6887\n",
            "Epoch 69/600\n",
            "16342/16342 [==============================] - 11s 699us/sample - loss: 0.6697 - categorical_accuracy: 0.7019 - val_loss: 0.6357 - val_categorical_accuracy: 0.7215\n",
            "Epoch 70/600\n",
            "16342/16342 [==============================] - 11s 700us/sample - loss: 0.6688 - categorical_accuracy: 0.7051 - val_loss: 0.6377 - val_categorical_accuracy: 0.7230\n",
            "Epoch 71/600\n",
            "16342/16342 [==============================] - 11s 702us/sample - loss: 0.6662 - categorical_accuracy: 0.7085 - val_loss: 0.6565 - val_categorical_accuracy: 0.7063\n",
            "Epoch 72/600\n",
            "16342/16342 [==============================] - 11s 700us/sample - loss: 0.6767 - categorical_accuracy: 0.7051 - val_loss: 0.6453 - val_categorical_accuracy: 0.7073\n",
            "Epoch 73/600\n",
            "16342/16342 [==============================] - 11s 698us/sample - loss: 0.6722 - categorical_accuracy: 0.7022 - val_loss: 0.6449 - val_categorical_accuracy: 0.7083\n",
            "Epoch 74/600\n",
            "16342/16342 [==============================] - 11s 698us/sample - loss: 0.6671 - categorical_accuracy: 0.7084 - val_loss: 0.6540 - val_categorical_accuracy: 0.7019\n",
            "Epoch 75/600\n",
            "16342/16342 [==============================] - 11s 700us/sample - loss: 0.6687 - categorical_accuracy: 0.7033 - val_loss: 0.6344 - val_categorical_accuracy: 0.7151\n",
            "Epoch 76/600\n",
            "16342/16342 [==============================] - 11s 701us/sample - loss: 0.6788 - categorical_accuracy: 0.6977 - val_loss: 0.6546 - val_categorical_accuracy: 0.7107\n",
            "Epoch 77/600\n",
            "16342/16342 [==============================] - 11s 701us/sample - loss: 0.6696 - categorical_accuracy: 0.7047 - val_loss: 0.6343 - val_categorical_accuracy: 0.7186\n",
            "Epoch 78/600\n",
            "16342/16342 [==============================] - 11s 698us/sample - loss: 0.6763 - categorical_accuracy: 0.7013 - val_loss: 0.6417 - val_categorical_accuracy: 0.7083\n",
            "Epoch 79/600\n",
            "16342/16342 [==============================] - 11s 698us/sample - loss: 0.6658 - categorical_accuracy: 0.7063 - val_loss: 0.6435 - val_categorical_accuracy: 0.7176\n",
            "Epoch 80/600\n",
            "16342/16342 [==============================] - 11s 697us/sample - loss: 0.6827 - categorical_accuracy: 0.6956 - val_loss: 0.6420 - val_categorical_accuracy: 0.7068\n",
            "Epoch 81/600\n",
            "16342/16342 [==============================] - 11s 699us/sample - loss: 0.6735 - categorical_accuracy: 0.7036 - val_loss: 0.6598 - val_categorical_accuracy: 0.7146\n",
            "Epoch 82/600\n",
            "16342/16342 [==============================] - 11s 699us/sample - loss: 0.6736 - categorical_accuracy: 0.7040 - val_loss: 0.6483 - val_categorical_accuracy: 0.7044\n",
            "Epoch 83/600\n",
            "16342/16342 [==============================] - 11s 697us/sample - loss: 0.6684 - categorical_accuracy: 0.7039 - val_loss: 0.6468 - val_categorical_accuracy: 0.7073\n",
            "Epoch 84/600\n",
            "16342/16342 [==============================] - 11s 698us/sample - loss: 0.6698 - categorical_accuracy: 0.7070 - val_loss: 0.6479 - val_categorical_accuracy: 0.7166\n",
            "Epoch 85/600\n",
            "16342/16342 [==============================] - 11s 698us/sample - loss: 0.6675 - categorical_accuracy: 0.7062 - val_loss: 0.6347 - val_categorical_accuracy: 0.7186\n",
            "Epoch 86/600\n",
            "16342/16342 [==============================] - 11s 699us/sample - loss: 0.6729 - categorical_accuracy: 0.7027 - val_loss: 0.6391 - val_categorical_accuracy: 0.7127\n",
            "Epoch 87/600\n",
            "16342/16342 [==============================] - 11s 698us/sample - loss: 0.6664 - categorical_accuracy: 0.7066 - val_loss: 0.6389 - val_categorical_accuracy: 0.7132\n",
            "Epoch 88/600\n",
            "16342/16342 [==============================] - 11s 702us/sample - loss: 0.6650 - categorical_accuracy: 0.7099 - val_loss: 0.6489 - val_categorical_accuracy: 0.7073\n",
            "Epoch 89/600\n",
            "16342/16342 [==============================] - 11s 699us/sample - loss: 0.6677 - categorical_accuracy: 0.7085 - val_loss: 0.6478 - val_categorical_accuracy: 0.7200\n",
            "Epoch 90/600\n",
            "16342/16342 [==============================] - 11s 699us/sample - loss: 0.6629 - categorical_accuracy: 0.7112 - val_loss: 0.6334 - val_categorical_accuracy: 0.7303\n",
            "Epoch 91/600\n",
            "16342/16342 [==============================] - 11s 698us/sample - loss: 0.6822 - categorical_accuracy: 0.6996 - val_loss: 0.6436 - val_categorical_accuracy: 0.7034\n",
            "Epoch 92/600\n",
            "16342/16342 [==============================] - 11s 698us/sample - loss: 0.6715 - categorical_accuracy: 0.7067 - val_loss: 0.6316 - val_categorical_accuracy: 0.7264\n",
            "Epoch 93/600\n",
            "16342/16342 [==============================] - 11s 698us/sample - loss: 0.6648 - categorical_accuracy: 0.7098 - val_loss: 0.6349 - val_categorical_accuracy: 0.7186\n",
            "Epoch 94/600\n",
            "16342/16342 [==============================] - 11s 699us/sample - loss: 0.6714 - categorical_accuracy: 0.7030 - val_loss: 0.6568 - val_categorical_accuracy: 0.7117\n",
            "Epoch 95/600\n",
            "16342/16342 [==============================] - 11s 699us/sample - loss: 0.6651 - categorical_accuracy: 0.7109 - val_loss: 0.6522 - val_categorical_accuracy: 0.7000\n",
            "Epoch 96/600\n",
            "16342/16342 [==============================] - 11s 703us/sample - loss: 0.6716 - categorical_accuracy: 0.7050 - val_loss: 0.6481 - val_categorical_accuracy: 0.7097\n",
            "Epoch 97/600\n",
            "16342/16342 [==============================] - 11s 699us/sample - loss: 0.6677 - categorical_accuracy: 0.7045 - val_loss: 0.6614 - val_categorical_accuracy: 0.7034\n",
            "Epoch 98/600\n",
            "16342/16342 [==============================] - 11s 699us/sample - loss: 0.6690 - categorical_accuracy: 0.7066 - val_loss: 0.6360 - val_categorical_accuracy: 0.7102\n",
            "Epoch 99/600\n",
            "16342/16342 [==============================] - 11s 698us/sample - loss: 0.6679 - categorical_accuracy: 0.7074 - val_loss: 0.6453 - val_categorical_accuracy: 0.7063\n",
            "Epoch 100/600\n",
            "16342/16342 [==============================] - 11s 698us/sample - loss: 0.6686 - categorical_accuracy: 0.7077 - val_loss: 0.6476 - val_categorical_accuracy: 0.7190\n",
            "Epoch 101/600\n",
            "16342/16342 [==============================] - 11s 697us/sample - loss: 0.6642 - categorical_accuracy: 0.7081 - val_loss: 0.6345 - val_categorical_accuracy: 0.7190\n",
            "Epoch 102/600\n",
            "16342/16342 [==============================] - 11s 699us/sample - loss: 0.6699 - categorical_accuracy: 0.7079 - val_loss: 0.6311 - val_categorical_accuracy: 0.7288\n",
            "Epoch 103/600\n",
            "16342/16342 [==============================] - 11s 698us/sample - loss: 0.6659 - categorical_accuracy: 0.7084 - val_loss: 0.6354 - val_categorical_accuracy: 0.7244\n",
            "Epoch 104/600\n",
            "16342/16342 [==============================] - 11s 702us/sample - loss: 0.6665 - categorical_accuracy: 0.7054 - val_loss: 0.6480 - val_categorical_accuracy: 0.7210\n",
            "Epoch 105/600\n",
            "16342/16342 [==============================] - 11s 701us/sample - loss: 0.6711 - categorical_accuracy: 0.7051 - val_loss: 0.6315 - val_categorical_accuracy: 0.7220\n",
            "Epoch 106/600\n",
            "16342/16342 [==============================] - 11s 699us/sample - loss: 0.6729 - categorical_accuracy: 0.7040 - val_loss: 0.6325 - val_categorical_accuracy: 0.7269\n",
            "Epoch 107/600\n",
            "16342/16342 [==============================] - 11s 700us/sample - loss: 0.6671 - categorical_accuracy: 0.7058 - val_loss: 0.6338 - val_categorical_accuracy: 0.7176\n",
            "Epoch 108/600\n",
            "16342/16342 [==============================] - 11s 702us/sample - loss: 0.6699 - categorical_accuracy: 0.7022 - val_loss: 0.6356 - val_categorical_accuracy: 0.7141\n",
            "Epoch 109/600\n",
            "16342/16342 [==============================] - 11s 700us/sample - loss: 0.6722 - categorical_accuracy: 0.7058 - val_loss: 0.6483 - val_categorical_accuracy: 0.6985\n",
            "Epoch 110/600\n",
            "16342/16342 [==============================] - 11s 698us/sample - loss: 0.6646 - categorical_accuracy: 0.7085 - val_loss: 0.6452 - val_categorical_accuracy: 0.7019\n",
            "Epoch 111/600\n",
            "16342/16342 [==============================] - 11s 700us/sample - loss: 0.6631 - categorical_accuracy: 0.7122 - val_loss: 0.6314 - val_categorical_accuracy: 0.7195\n",
            "Epoch 112/600\n",
            "16342/16342 [==============================] - 11s 703us/sample - loss: 0.6614 - categorical_accuracy: 0.7118 - val_loss: 0.6331 - val_categorical_accuracy: 0.7132\n",
            "Epoch 113/600\n",
            "16342/16342 [==============================] - 11s 699us/sample - loss: 0.6713 - categorical_accuracy: 0.7031 - val_loss: 0.6314 - val_categorical_accuracy: 0.7293\n",
            "Epoch 114/600\n",
            "16342/16342 [==============================] - 11s 700us/sample - loss: 0.6723 - categorical_accuracy: 0.7055 - val_loss: 0.6452 - val_categorical_accuracy: 0.7190\n",
            "Epoch 115/600\n",
            "16342/16342 [==============================] - 11s 701us/sample - loss: 0.6617 - categorical_accuracy: 0.7114 - val_loss: 0.6299 - val_categorical_accuracy: 0.7220\n",
            "Epoch 116/600\n",
            "16342/16342 [==============================] - 11s 700us/sample - loss: 0.6668 - categorical_accuracy: 0.7053 - val_loss: 0.6450 - val_categorical_accuracy: 0.7078\n",
            "Epoch 117/600\n",
            "16342/16342 [==============================] - 11s 700us/sample - loss: 0.6678 - categorical_accuracy: 0.7083 - val_loss: 0.6311 - val_categorical_accuracy: 0.7244\n",
            "Epoch 118/600\n",
            "16342/16342 [==============================] - 11s 700us/sample - loss: 0.6645 - categorical_accuracy: 0.7084 - val_loss: 0.6431 - val_categorical_accuracy: 0.7205\n",
            "Epoch 119/600\n",
            "16342/16342 [==============================] - 11s 703us/sample - loss: 0.6695 - categorical_accuracy: 0.7054 - val_loss: 0.6322 - val_categorical_accuracy: 0.7230\n",
            "Epoch 120/600\n",
            "16342/16342 [==============================] - 11s 699us/sample - loss: 0.6596 - categorical_accuracy: 0.7147 - val_loss: 0.6302 - val_categorical_accuracy: 0.7274\n",
            "Epoch 121/600\n",
            "16342/16342 [==============================] - 11s 699us/sample - loss: 0.6707 - categorical_accuracy: 0.7031 - val_loss: 0.6318 - val_categorical_accuracy: 0.7225\n",
            "Epoch 122/600\n",
            "16342/16342 [==============================] - 11s 697us/sample - loss: 0.6641 - categorical_accuracy: 0.7066 - val_loss: 0.6343 - val_categorical_accuracy: 0.7176\n",
            "Epoch 123/600\n",
            "16342/16342 [==============================] - 11s 701us/sample - loss: 0.6646 - categorical_accuracy: 0.7099 - val_loss: 0.6715 - val_categorical_accuracy: 0.6985\n",
            "Epoch 124/600\n",
            "16342/16342 [==============================] - 11s 704us/sample - loss: 0.6778 - categorical_accuracy: 0.7008 - val_loss: 0.6336 - val_categorical_accuracy: 0.7215\n",
            "Epoch 125/600\n",
            "16342/16342 [==============================] - 11s 698us/sample - loss: 0.6686 - categorical_accuracy: 0.7045 - val_loss: 0.6330 - val_categorical_accuracy: 0.7200\n",
            "Epoch 126/600\n",
            "16342/16342 [==============================] - 11s 698us/sample - loss: 0.6683 - categorical_accuracy: 0.7070 - val_loss: 0.6305 - val_categorical_accuracy: 0.7190\n",
            "Epoch 127/600\n",
            "16342/16342 [==============================] - 11s 699us/sample - loss: 0.6621 - categorical_accuracy: 0.7107 - val_loss: 0.6346 - val_categorical_accuracy: 0.7220\n",
            "Epoch 128/600\n",
            "16342/16342 [==============================] - 11s 699us/sample - loss: 0.6668 - categorical_accuracy: 0.7050 - val_loss: 0.6419 - val_categorical_accuracy: 0.7078\n",
            "Epoch 129/600\n",
            "16342/16342 [==============================] - 11s 702us/sample - loss: 0.6622 - categorical_accuracy: 0.7109 - val_loss: 0.6566 - val_categorical_accuracy: 0.6955\n",
            "Epoch 130/600\n",
            "16342/16342 [==============================] - 11s 699us/sample - loss: 0.6673 - categorical_accuracy: 0.7057 - val_loss: 0.6621 - val_categorical_accuracy: 0.6931\n",
            "Epoch 131/600\n",
            "16342/16342 [==============================] - 11s 699us/sample - loss: 0.6738 - categorical_accuracy: 0.7019 - val_loss: 0.6306 - val_categorical_accuracy: 0.7234\n",
            "Epoch 132/600\n",
            "16342/16342 [==============================] - 11s 699us/sample - loss: 0.6624 - categorical_accuracy: 0.7109 - val_loss: 0.6346 - val_categorical_accuracy: 0.7166\n",
            "Epoch 133/600\n",
            "16342/16342 [==============================] - 11s 698us/sample - loss: 0.6581 - categorical_accuracy: 0.7134 - val_loss: 0.6433 - val_categorical_accuracy: 0.7073\n",
            "Epoch 134/600\n",
            "16342/16342 [==============================] - 11s 698us/sample - loss: 0.6715 - categorical_accuracy: 0.7044 - val_loss: 0.6448 - val_categorical_accuracy: 0.7097\n",
            "Epoch 135/600\n",
            "16342/16342 [==============================] - 11s 700us/sample - loss: 0.6618 - categorical_accuracy: 0.7125 - val_loss: 0.6316 - val_categorical_accuracy: 0.7230\n",
            "Epoch 136/600\n",
            "16342/16342 [==============================] - 11s 703us/sample - loss: 0.6673 - categorical_accuracy: 0.7076 - val_loss: 0.6372 - val_categorical_accuracy: 0.7093\n",
            "Epoch 137/600\n",
            "16342/16342 [==============================] - 11s 698us/sample - loss: 0.6604 - categorical_accuracy: 0.7125 - val_loss: 0.6507 - val_categorical_accuracy: 0.7029\n",
            "Epoch 138/600\n",
            "16342/16342 [==============================] - 11s 699us/sample - loss: 0.6685 - categorical_accuracy: 0.7073 - val_loss: 0.6324 - val_categorical_accuracy: 0.7161\n",
            "Epoch 139/600\n",
            "16342/16342 [==============================] - 11s 698us/sample - loss: 0.6652 - categorical_accuracy: 0.7114 - val_loss: 0.6294 - val_categorical_accuracy: 0.7220\n",
            "Epoch 140/600\n",
            "16342/16342 [==============================] - 11s 697us/sample - loss: 0.6712 - categorical_accuracy: 0.7039 - val_loss: 0.6358 - val_categorical_accuracy: 0.7234\n",
            "Epoch 141/600\n",
            "16342/16342 [==============================] - 11s 698us/sample - loss: 0.6617 - categorical_accuracy: 0.7130 - val_loss: 0.6725 - val_categorical_accuracy: 0.6926\n",
            "Epoch 142/600\n",
            "16342/16342 [==============================] - 11s 697us/sample - loss: 0.6633 - categorical_accuracy: 0.7107 - val_loss: 0.6303 - val_categorical_accuracy: 0.7234\n",
            "Epoch 143/600\n",
            "16342/16342 [==============================] - 11s 698us/sample - loss: 0.6601 - categorical_accuracy: 0.7126 - val_loss: 0.6666 - val_categorical_accuracy: 0.6946\n",
            "Epoch 144/600\n",
            "16342/16342 [==============================] - 11s 700us/sample - loss: 0.6715 - categorical_accuracy: 0.7029 - val_loss: 0.6331 - val_categorical_accuracy: 0.7332\n",
            "Epoch 145/600\n",
            "16342/16342 [==============================] - 11s 698us/sample - loss: 0.6603 - categorical_accuracy: 0.7114 - val_loss: 0.6287 - val_categorical_accuracy: 0.7225\n",
            "Epoch 146/600\n",
            "16342/16342 [==============================] - 11s 703us/sample - loss: 0.6591 - categorical_accuracy: 0.7122 - val_loss: 0.6296 - val_categorical_accuracy: 0.7259\n",
            "Epoch 147/600\n",
            "16342/16342 [==============================] - 11s 699us/sample - loss: 0.6676 - categorical_accuracy: 0.7068 - val_loss: 0.6331 - val_categorical_accuracy: 0.7337\n",
            "Epoch 148/600\n",
            "16342/16342 [==============================] - 11s 699us/sample - loss: 0.6614 - categorical_accuracy: 0.7125 - val_loss: 0.6300 - val_categorical_accuracy: 0.7215\n",
            "Epoch 149/600\n",
            "16342/16342 [==============================] - 11s 700us/sample - loss: 0.6617 - categorical_accuracy: 0.7124 - val_loss: 0.6297 - val_categorical_accuracy: 0.7249\n",
            "Epoch 150/600\n",
            "16342/16342 [==============================] - 11s 703us/sample - loss: 0.6630 - categorical_accuracy: 0.7117 - val_loss: 0.6362 - val_categorical_accuracy: 0.7102\n",
            "Epoch 151/600\n",
            "16342/16342 [==============================] - 11s 699us/sample - loss: 0.6634 - categorical_accuracy: 0.7114 - val_loss: 0.6293 - val_categorical_accuracy: 0.7264\n",
            "Epoch 152/600\n",
            "16342/16342 [==============================] - 11s 697us/sample - loss: 0.6628 - categorical_accuracy: 0.7112 - val_loss: 0.6416 - val_categorical_accuracy: 0.7244\n",
            "Epoch 153/600\n",
            "16342/16342 [==============================] - 11s 699us/sample - loss: 0.6595 - categorical_accuracy: 0.7145 - val_loss: 0.6473 - val_categorical_accuracy: 0.7048\n",
            "Epoch 154/600\n",
            "16342/16342 [==============================] - 11s 697us/sample - loss: 0.6624 - categorical_accuracy: 0.7103 - val_loss: 0.6272 - val_categorical_accuracy: 0.7244\n",
            "Epoch 155/600\n",
            "16342/16342 [==============================] - 11s 699us/sample - loss: 0.6739 - categorical_accuracy: 0.7043 - val_loss: 0.6579 - val_categorical_accuracy: 0.7004\n",
            "Epoch 156/600\n",
            "16342/16342 [==============================] - 11s 698us/sample - loss: 0.6643 - categorical_accuracy: 0.7081 - val_loss: 0.6277 - val_categorical_accuracy: 0.7259\n",
            "Epoch 157/600\n",
            "16342/16342 [==============================] - 11s 699us/sample - loss: 0.6631 - categorical_accuracy: 0.7103 - val_loss: 0.6759 - val_categorical_accuracy: 0.6955\n",
            "Epoch 158/600\n",
            "16342/16342 [==============================] - 11s 703us/sample - loss: 0.6675 - categorical_accuracy: 0.7088 - val_loss: 0.6310 - val_categorical_accuracy: 0.7166\n",
            "Epoch 159/600\n",
            "16342/16342 [==============================] - 11s 698us/sample - loss: 0.6623 - categorical_accuracy: 0.7108 - val_loss: 0.6344 - val_categorical_accuracy: 0.7137\n",
            "Epoch 160/600\n",
            "16342/16342 [==============================] - 11s 700us/sample - loss: 0.6610 - categorical_accuracy: 0.7118 - val_loss: 0.6296 - val_categorical_accuracy: 0.7186\n",
            "Epoch 161/600\n",
            "16342/16342 [==============================] - 11s 700us/sample - loss: 0.6630 - categorical_accuracy: 0.7109 - val_loss: 0.6326 - val_categorical_accuracy: 0.7318\n",
            "Epoch 162/600\n",
            "16342/16342 [==============================] - 11s 703us/sample - loss: 0.6589 - categorical_accuracy: 0.7140 - val_loss: 0.6336 - val_categorical_accuracy: 0.7298\n",
            "Epoch 163/600\n",
            "16342/16342 [==============================] - 11s 698us/sample - loss: 0.6599 - categorical_accuracy: 0.7128 - val_loss: 0.6276 - val_categorical_accuracy: 0.7264\n",
            "Epoch 164/600\n",
            "16342/16342 [==============================] - 11s 698us/sample - loss: 0.6606 - categorical_accuracy: 0.7107 - val_loss: 0.6299 - val_categorical_accuracy: 0.7303\n",
            "Epoch 165/600\n",
            "16342/16342 [==============================] - 11s 699us/sample - loss: 0.6633 - categorical_accuracy: 0.7128 - val_loss: 0.6326 - val_categorical_accuracy: 0.7298\n",
            "Epoch 166/600\n",
            "16342/16342 [==============================] - 11s 697us/sample - loss: 0.6686 - categorical_accuracy: 0.7068 - val_loss: 0.6268 - val_categorical_accuracy: 0.7244\n",
            "Epoch 167/600\n",
            "16342/16342 [==============================] - 11s 698us/sample - loss: 0.6616 - categorical_accuracy: 0.7115 - val_loss: 0.6332 - val_categorical_accuracy: 0.7200\n",
            "Epoch 168/600\n",
            "16342/16342 [==============================] - 11s 698us/sample - loss: 0.6605 - categorical_accuracy: 0.7123 - val_loss: 0.6299 - val_categorical_accuracy: 0.7249\n",
            "Epoch 169/600\n",
            "16342/16342 [==============================] - 11s 699us/sample - loss: 0.6592 - categorical_accuracy: 0.7153 - val_loss: 0.6343 - val_categorical_accuracy: 0.7249\n",
            "Epoch 170/600\n",
            "16342/16342 [==============================] - 11s 703us/sample - loss: 0.6629 - categorical_accuracy: 0.7063 - val_loss: 0.6321 - val_categorical_accuracy: 0.7293\n",
            "Epoch 171/600\n",
            "16342/16342 [==============================] - 11s 700us/sample - loss: 0.6597 - categorical_accuracy: 0.7126 - val_loss: 0.6440 - val_categorical_accuracy: 0.7112\n",
            "Epoch 172/600\n",
            "16342/16342 [==============================] - 11s 699us/sample - loss: 0.6719 - categorical_accuracy: 0.7046 - val_loss: 0.6282 - val_categorical_accuracy: 0.7283\n",
            "Epoch 173/600\n",
            "16342/16342 [==============================] - 11s 702us/sample - loss: 0.6635 - categorical_accuracy: 0.7087 - val_loss: 0.6270 - val_categorical_accuracy: 0.7288\n",
            "Epoch 174/600\n",
            "16342/16342 [==============================] - 11s 700us/sample - loss: 0.6610 - categorical_accuracy: 0.7124 - val_loss: 0.6283 - val_categorical_accuracy: 0.7215\n",
            "Epoch 175/600\n",
            "16342/16342 [==============================] - 11s 699us/sample - loss: 0.6633 - categorical_accuracy: 0.7111 - val_loss: 0.6269 - val_categorical_accuracy: 0.7269\n",
            "Epoch 176/600\n",
            "16342/16342 [==============================] - 11s 698us/sample - loss: 0.6622 - categorical_accuracy: 0.7090 - val_loss: 0.6275 - val_categorical_accuracy: 0.7249\n",
            "Epoch 177/600\n",
            "16342/16342 [==============================] - 11s 699us/sample - loss: 0.6573 - categorical_accuracy: 0.7159 - val_loss: 0.6264 - val_categorical_accuracy: 0.7264\n",
            "Epoch 178/600\n",
            "16342/16342 [==============================] - 11s 699us/sample - loss: 0.6579 - categorical_accuracy: 0.7147 - val_loss: 0.6265 - val_categorical_accuracy: 0.7293\n",
            "Epoch 179/600\n",
            "16342/16342 [==============================] - 11s 703us/sample - loss: 0.6638 - categorical_accuracy: 0.7095 - val_loss: 0.6626 - val_categorical_accuracy: 0.7078\n",
            "Epoch 180/600\n",
            "16342/16342 [==============================] - 11s 699us/sample - loss: 0.6767 - categorical_accuracy: 0.7010 - val_loss: 0.6341 - val_categorical_accuracy: 0.7171\n",
            "Epoch 181/600\n",
            "16342/16342 [==============================] - 11s 699us/sample - loss: 0.6642 - categorical_accuracy: 0.7100 - val_loss: 0.6298 - val_categorical_accuracy: 0.7244\n",
            "Epoch 182/600\n",
            "16342/16342 [==============================] - 11s 699us/sample - loss: 0.6612 - categorical_accuracy: 0.7155 - val_loss: 0.6614 - val_categorical_accuracy: 0.6951\n",
            "Epoch 183/600\n",
            "16342/16342 [==============================] - 12s 705us/sample - loss: 0.6607 - categorical_accuracy: 0.7122 - val_loss: 0.6288 - val_categorical_accuracy: 0.7313\n",
            "Epoch 184/600\n",
            "16342/16342 [==============================] - 11s 700us/sample - loss: 0.6580 - categorical_accuracy: 0.7150 - val_loss: 0.6329 - val_categorical_accuracy: 0.7298\n",
            "Epoch 185/600\n",
            "16342/16342 [==============================] - 12s 704us/sample - loss: 0.6590 - categorical_accuracy: 0.7115 - val_loss: 0.6266 - val_categorical_accuracy: 0.7254\n",
            "Epoch 186/600\n",
            "16342/16342 [==============================] - 11s 698us/sample - loss: 0.6687 - categorical_accuracy: 0.7078 - val_loss: 0.6601 - val_categorical_accuracy: 0.7014\n",
            "Epoch 187/600\n",
            "16342/16342 [==============================] - 11s 699us/sample - loss: 0.6578 - categorical_accuracy: 0.7148 - val_loss: 0.6267 - val_categorical_accuracy: 0.7269\n",
            "Epoch 188/600\n",
            "16342/16342 [==============================] - 11s 702us/sample - loss: 0.6578 - categorical_accuracy: 0.7137 - val_loss: 0.6284 - val_categorical_accuracy: 0.7215\n",
            "Epoch 189/600\n",
            "16342/16342 [==============================] - 11s 702us/sample - loss: 0.6620 - categorical_accuracy: 0.7092 - val_loss: 0.6324 - val_categorical_accuracy: 0.7220\n",
            "Epoch 190/600\n",
            "16342/16342 [==============================] - 11s 698us/sample - loss: 0.6589 - categorical_accuracy: 0.7133 - val_loss: 0.6321 - val_categorical_accuracy: 0.7166\n",
            "Epoch 191/600\n",
            "16342/16342 [==============================] - 11s 698us/sample - loss: 0.6637 - categorical_accuracy: 0.7102 - val_loss: 0.6415 - val_categorical_accuracy: 0.7137\n",
            "Epoch 192/600\n",
            "16342/16342 [==============================] - 11s 699us/sample - loss: 0.6700 - categorical_accuracy: 0.7043 - val_loss: 0.6310 - val_categorical_accuracy: 0.7249\n",
            "Epoch 193/600\n",
            "16342/16342 [==============================] - 11s 699us/sample - loss: 0.6606 - categorical_accuracy: 0.7149 - val_loss: 0.6306 - val_categorical_accuracy: 0.7186\n",
            "Epoch 194/600\n",
            "16342/16342 [==============================] - 12s 704us/sample - loss: 0.6600 - categorical_accuracy: 0.7117 - val_loss: 0.6287 - val_categorical_accuracy: 0.7176\n",
            "Epoch 195/600\n",
            "16342/16342 [==============================] - 11s 700us/sample - loss: 0.6678 - categorical_accuracy: 0.7065 - val_loss: 0.6407 - val_categorical_accuracy: 0.7171\n",
            "Epoch 196/600\n",
            "16342/16342 [==============================] - 11s 698us/sample - loss: 0.6658 - categorical_accuracy: 0.7071 - val_loss: 0.6433 - val_categorical_accuracy: 0.7088\n",
            "Epoch 197/600\n",
            "16342/16342 [==============================] - 11s 700us/sample - loss: 0.6590 - categorical_accuracy: 0.7110 - val_loss: 0.6410 - val_categorical_accuracy: 0.7137\n",
            "Epoch 198/600\n",
            "16342/16342 [==============================] - 11s 701us/sample - loss: 0.6560 - categorical_accuracy: 0.7141 - val_loss: 0.6531 - val_categorical_accuracy: 0.7029\n",
            "Epoch 199/600\n",
            "16342/16342 [==============================] - 11s 701us/sample - loss: 0.6602 - categorical_accuracy: 0.7098 - val_loss: 0.6262 - val_categorical_accuracy: 0.7249\n",
            "Epoch 200/600\n",
            "16342/16342 [==============================] - 11s 699us/sample - loss: 0.6585 - categorical_accuracy: 0.7135 - val_loss: 0.6537 - val_categorical_accuracy: 0.6985\n",
            "Epoch 201/600\n",
            "16342/16342 [==============================] - 11s 697us/sample - loss: 0.6636 - categorical_accuracy: 0.7086 - val_loss: 0.6375 - val_categorical_accuracy: 0.7146\n",
            "Epoch 202/600\n",
            "16342/16342 [==============================] - 11s 698us/sample - loss: 0.6566 - categorical_accuracy: 0.7143 - val_loss: 0.6317 - val_categorical_accuracy: 0.7293\n",
            "Epoch 203/600\n",
            "16342/16342 [==============================] - 11s 703us/sample - loss: 0.6583 - categorical_accuracy: 0.7158 - val_loss: 0.6316 - val_categorical_accuracy: 0.7269\n",
            "Epoch 204/600\n",
            "16342/16342 [==============================] - 11s 701us/sample - loss: 0.6595 - categorical_accuracy: 0.7112 - val_loss: 0.6363 - val_categorical_accuracy: 0.7127\n",
            "Epoch 205/600\n",
            "16342/16342 [==============================] - 11s 697us/sample - loss: 0.6605 - categorical_accuracy: 0.7129 - val_loss: 0.6414 - val_categorical_accuracy: 0.7225\n",
            "Epoch 206/600\n",
            "16342/16342 [==============================] - 11s 699us/sample - loss: 0.6639 - categorical_accuracy: 0.7082 - val_loss: 0.6494 - val_categorical_accuracy: 0.7004\n",
            "Epoch 207/600\n",
            "16342/16342 [==============================] - 11s 697us/sample - loss: 0.6645 - categorical_accuracy: 0.7102 - val_loss: 0.6325 - val_categorical_accuracy: 0.7234\n",
            "Epoch 208/600\n",
            "16342/16342 [==============================] - 11s 699us/sample - loss: 0.6606 - categorical_accuracy: 0.7117 - val_loss: 0.6252 - val_categorical_accuracy: 0.7264\n",
            "Epoch 209/600\n",
            "16342/16342 [==============================] - 11s 699us/sample - loss: 0.6698 - categorical_accuracy: 0.7058 - val_loss: 0.6361 - val_categorical_accuracy: 0.7279\n",
            "Epoch 210/600\n",
            "16342/16342 [==============================] - 11s 702us/sample - loss: 0.6584 - categorical_accuracy: 0.7144 - val_loss: 0.6290 - val_categorical_accuracy: 0.7195\n",
            "Epoch 211/600\n",
            "16342/16342 [==============================] - 11s 699us/sample - loss: 0.6588 - categorical_accuracy: 0.7105 - val_loss: 0.6270 - val_categorical_accuracy: 0.7249\n",
            "Epoch 212/600\n",
            "16342/16342 [==============================] - 11s 699us/sample - loss: 0.6643 - categorical_accuracy: 0.7111 - val_loss: 0.6354 - val_categorical_accuracy: 0.7313\n",
            "Epoch 213/600\n",
            "16342/16342 [==============================] - 11s 697us/sample - loss: 0.6604 - categorical_accuracy: 0.7101 - val_loss: 0.6272 - val_categorical_accuracy: 0.7254\n",
            "Epoch 214/600\n",
            "16342/16342 [==============================] - 11s 696us/sample - loss: 0.6568 - categorical_accuracy: 0.7144 - val_loss: 0.6272 - val_categorical_accuracy: 0.7318\n",
            "Epoch 215/600\n",
            "16342/16342 [==============================] - 11s 699us/sample - loss: 0.6621 - categorical_accuracy: 0.7123 - val_loss: 0.6281 - val_categorical_accuracy: 0.7293\n",
            "Epoch 216/600\n",
            "16342/16342 [==============================] - 11s 699us/sample - loss: 0.6585 - categorical_accuracy: 0.7138 - val_loss: 0.6497 - val_categorical_accuracy: 0.7048\n",
            "Epoch 217/600\n",
            "16342/16342 [==============================] - 11s 699us/sample - loss: 0.6598 - categorical_accuracy: 0.7135 - val_loss: 0.6309 - val_categorical_accuracy: 0.7200\n",
            "Epoch 218/600\n",
            "16342/16342 [==============================] - 12s 704us/sample - loss: 0.6628 - categorical_accuracy: 0.7128 - val_loss: 0.6332 - val_categorical_accuracy: 0.7332\n",
            "Epoch 219/600\n",
            "16342/16342 [==============================] - 11s 699us/sample - loss: 0.6577 - categorical_accuracy: 0.7137 - val_loss: 0.6257 - val_categorical_accuracy: 0.7254\n",
            "Epoch 220/600\n",
            "16342/16342 [==============================] - 11s 698us/sample - loss: 0.6612 - categorical_accuracy: 0.7121 - val_loss: 0.6319 - val_categorical_accuracy: 0.7190\n",
            "Epoch 221/600\n",
            "16342/16342 [==============================] - 11s 698us/sample - loss: 0.6595 - categorical_accuracy: 0.7117 - val_loss: 0.6309 - val_categorical_accuracy: 0.7239\n",
            "Epoch 222/600\n",
            "16342/16342 [==============================] - 11s 700us/sample - loss: 0.6605 - categorical_accuracy: 0.7137 - val_loss: 0.6256 - val_categorical_accuracy: 0.7283\n",
            "Epoch 223/600\n",
            "16342/16342 [==============================] - 11s 699us/sample - loss: 0.6582 - categorical_accuracy: 0.7158 - val_loss: 0.6424 - val_categorical_accuracy: 0.7078\n",
            "Epoch 224/600\n",
            "16342/16342 [==============================] - 11s 702us/sample - loss: 0.6632 - categorical_accuracy: 0.7112 - val_loss: 0.6712 - val_categorical_accuracy: 0.6951\n",
            "Epoch 225/600\n",
            "16342/16342 [==============================] - 11s 699us/sample - loss: 0.6565 - categorical_accuracy: 0.7125 - val_loss: 0.6304 - val_categorical_accuracy: 0.7156\n",
            "Epoch 226/600\n",
            "16342/16342 [==============================] - 11s 699us/sample - loss: 0.6608 - categorical_accuracy: 0.7133 - val_loss: 0.6278 - val_categorical_accuracy: 0.7195\n",
            "Epoch 227/600\n",
            "16342/16342 [==============================] - 11s 698us/sample - loss: 0.6626 - categorical_accuracy: 0.7109 - val_loss: 0.6306 - val_categorical_accuracy: 0.7190\n",
            "Epoch 228/600\n",
            "16342/16342 [==============================] - 11s 700us/sample - loss: 0.6578 - categorical_accuracy: 0.7144 - val_loss: 0.6262 - val_categorical_accuracy: 0.7244\n",
            "Epoch 229/600\n",
            "16342/16342 [==============================] - 11s 700us/sample - loss: 0.6587 - categorical_accuracy: 0.7129 - val_loss: 0.6257 - val_categorical_accuracy: 0.7288\n",
            "Epoch 230/600\n",
            "16342/16342 [==============================] - 11s 701us/sample - loss: 0.6538 - categorical_accuracy: 0.7202 - val_loss: 0.6256 - val_categorical_accuracy: 0.7298\n",
            "Epoch 231/600\n",
            "16342/16342 [==============================] - 11s 699us/sample - loss: 0.6577 - categorical_accuracy: 0.7157 - val_loss: 0.6318 - val_categorical_accuracy: 0.7161\n",
            "Epoch 232/600\n",
            "16342/16342 [==============================] - 11s 703us/sample - loss: 0.6553 - categorical_accuracy: 0.7181 - val_loss: 0.6354 - val_categorical_accuracy: 0.7230\n",
            "Epoch 233/600\n",
            "16342/16342 [==============================] - 11s 702us/sample - loss: 0.6598 - categorical_accuracy: 0.7123 - val_loss: 0.6284 - val_categorical_accuracy: 0.7298\n",
            "Epoch 234/600\n",
            "16342/16342 [==============================] - 11s 699us/sample - loss: 0.6562 - categorical_accuracy: 0.7155 - val_loss: 0.6250 - val_categorical_accuracy: 0.7205\n",
            "Epoch 235/600\n",
            "16342/16342 [==============================] - 11s 699us/sample - loss: 0.6623 - categorical_accuracy: 0.7117 - val_loss: 0.6253 - val_categorical_accuracy: 0.7303\n",
            "Epoch 236/600\n",
            "16342/16342 [==============================] - 11s 703us/sample - loss: 0.6578 - categorical_accuracy: 0.7138 - val_loss: 0.6315 - val_categorical_accuracy: 0.7269\n",
            "Epoch 237/600\n",
            "16342/16342 [==============================] - 11s 701us/sample - loss: 0.6652 - categorical_accuracy: 0.7109 - val_loss: 0.6598 - val_categorical_accuracy: 0.7034\n",
            "Epoch 238/600\n",
            "16342/16342 [==============================] - 11s 697us/sample - loss: 0.6648 - categorical_accuracy: 0.7101 - val_loss: 0.6404 - val_categorical_accuracy: 0.7102\n",
            "Epoch 239/600\n",
            "16342/16342 [==============================] - 11s 698us/sample - loss: 0.6572 - categorical_accuracy: 0.7147 - val_loss: 0.6340 - val_categorical_accuracy: 0.7264\n",
            "Epoch 240/600\n",
            "16342/16342 [==============================] - 11s 699us/sample - loss: 0.6561 - categorical_accuracy: 0.7151 - val_loss: 0.6256 - val_categorical_accuracy: 0.7283\n",
            "Epoch 241/600\n",
            "16342/16342 [==============================] - 11s 697us/sample - loss: 0.6650 - categorical_accuracy: 0.7101 - val_loss: 0.6301 - val_categorical_accuracy: 0.7220\n",
            "Epoch 242/600\n",
            "16342/16342 [==============================] - 11s 699us/sample - loss: 0.6572 - categorical_accuracy: 0.7137 - val_loss: 0.6262 - val_categorical_accuracy: 0.7259\n",
            "Epoch 243/600\n",
            "16342/16342 [==============================] - 11s 701us/sample - loss: 0.6564 - categorical_accuracy: 0.7171 - val_loss: 0.6261 - val_categorical_accuracy: 0.7337\n",
            "Epoch 244/600\n",
            "16342/16342 [==============================] - 11s 700us/sample - loss: 0.6598 - categorical_accuracy: 0.7127 - val_loss: 0.6787 - val_categorical_accuracy: 0.6887\n",
            "Epoch 245/600\n",
            "16342/16342 [==============================] - 11s 699us/sample - loss: 0.6647 - categorical_accuracy: 0.7113 - val_loss: 0.6497 - val_categorical_accuracy: 0.7044\n",
            "Epoch 246/600\n",
            "16342/16342 [==============================] - 11s 698us/sample - loss: 0.6615 - categorical_accuracy: 0.7117 - val_loss: 0.6251 - val_categorical_accuracy: 0.7225\n",
            "Epoch 247/600\n",
            "16342/16342 [==============================] - 11s 699us/sample - loss: 0.6580 - categorical_accuracy: 0.7137 - val_loss: 0.6625 - val_categorical_accuracy: 0.7029\n",
            "Epoch 248/600\n",
            "16342/16342 [==============================] - 11s 703us/sample - loss: 0.6593 - categorical_accuracy: 0.7128 - val_loss: 0.6492 - val_categorical_accuracy: 0.7200\n",
            "Epoch 249/600\n",
            "16342/16342 [==============================] - 11s 700us/sample - loss: 0.6647 - categorical_accuracy: 0.7082 - val_loss: 0.6495 - val_categorical_accuracy: 0.7029\n",
            "Epoch 250/600\n",
            "16342/16342 [==============================] - 11s 700us/sample - loss: 0.6562 - categorical_accuracy: 0.7160 - val_loss: 0.6881 - val_categorical_accuracy: 0.6867\n",
            "Epoch 251/600\n",
            "16342/16342 [==============================] - 11s 703us/sample - loss: 0.6623 - categorical_accuracy: 0.7095 - val_loss: 0.6359 - val_categorical_accuracy: 0.7308\n",
            "Epoch 252/600\n",
            "16342/16342 [==============================] - 11s 700us/sample - loss: 0.6554 - categorical_accuracy: 0.7174 - val_loss: 0.6292 - val_categorical_accuracy: 0.7303\n",
            "Epoch 253/600\n",
            "16342/16342 [==============================] - 11s 700us/sample - loss: 0.6563 - categorical_accuracy: 0.7134 - val_loss: 0.6256 - val_categorical_accuracy: 0.7220\n",
            "Epoch 254/600\n",
            "16342/16342 [==============================] - 12s 704us/sample - loss: 0.6589 - categorical_accuracy: 0.7152 - val_loss: 0.6278 - val_categorical_accuracy: 0.7195\n",
            "Epoch 255/600\n",
            "16342/16342 [==============================] - 11s 698us/sample - loss: 0.6562 - categorical_accuracy: 0.7134 - val_loss: 0.6307 - val_categorical_accuracy: 0.7171\n",
            "Epoch 256/600\n",
            "16342/16342 [==============================] - 11s 699us/sample - loss: 0.6560 - categorical_accuracy: 0.7175 - val_loss: 0.6295 - val_categorical_accuracy: 0.7234\n",
            "Epoch 257/600\n",
            "16342/16342 [==============================] - 11s 698us/sample - loss: 0.6564 - categorical_accuracy: 0.7163 - val_loss: 0.6268 - val_categorical_accuracy: 0.7195\n",
            "Epoch 258/600\n",
            "16342/16342 [==============================] - 11s 696us/sample - loss: 0.6542 - categorical_accuracy: 0.7185 - val_loss: 0.6304 - val_categorical_accuracy: 0.7215\n",
            "Epoch 259/600\n",
            "16342/16342 [==============================] - 11s 698us/sample - loss: 0.6606 - categorical_accuracy: 0.7145 - val_loss: 0.6310 - val_categorical_accuracy: 0.7195\n",
            "Epoch 260/600\n",
            "16342/16342 [==============================] - 11s 698us/sample - loss: 0.6599 - categorical_accuracy: 0.7116 - val_loss: 0.6448 - val_categorical_accuracy: 0.7102\n",
            "Epoch 261/600\n",
            "16342/16342 [==============================] - 11s 699us/sample - loss: 0.6550 - categorical_accuracy: 0.7186 - val_loss: 0.6267 - val_categorical_accuracy: 0.7283\n",
            "Epoch 262/600\n",
            "16342/16342 [==============================] - 11s 700us/sample - loss: 0.6613 - categorical_accuracy: 0.7104 - val_loss: 0.6455 - val_categorical_accuracy: 0.7190\n",
            "Epoch 263/600\n",
            "16342/16342 [==============================] - 11s 702us/sample - loss: 0.6640 - categorical_accuracy: 0.7128 - val_loss: 0.6295 - val_categorical_accuracy: 0.7249\n",
            "Epoch 264/600\n",
            "16342/16342 [==============================] - 11s 699us/sample - loss: 0.6576 - categorical_accuracy: 0.7159 - val_loss: 0.6344 - val_categorical_accuracy: 0.7137\n",
            "Epoch 265/600\n",
            "16342/16342 [==============================] - 11s 698us/sample - loss: 0.6543 - categorical_accuracy: 0.7169 - val_loss: 0.6301 - val_categorical_accuracy: 0.7205\n",
            "Epoch 266/600\n",
            "16342/16342 [==============================] - 11s 698us/sample - loss: 0.6568 - categorical_accuracy: 0.7156 - val_loss: 0.6363 - val_categorical_accuracy: 0.7127\n",
            "Epoch 267/600\n",
            "16342/16342 [==============================] - 11s 703us/sample - loss: 0.6557 - categorical_accuracy: 0.7159 - val_loss: 0.6269 - val_categorical_accuracy: 0.7244\n",
            "Epoch 268/600\n",
            "16342/16342 [==============================] - 11s 700us/sample - loss: 0.6559 - categorical_accuracy: 0.7148 - val_loss: 0.6314 - val_categorical_accuracy: 0.7176\n",
            "Epoch 269/600\n",
            "16342/16342 [==============================] - 11s 700us/sample - loss: 0.6546 - categorical_accuracy: 0.7180 - val_loss: 0.6301 - val_categorical_accuracy: 0.7190\n",
            "Epoch 270/600\n",
            "16342/16342 [==============================] - 11s 698us/sample - loss: 0.6605 - categorical_accuracy: 0.7132 - val_loss: 0.6309 - val_categorical_accuracy: 0.7146\n",
            "Epoch 271/600\n",
            "16342/16342 [==============================] - 11s 698us/sample - loss: 0.6572 - categorical_accuracy: 0.7163 - val_loss: 0.6285 - val_categorical_accuracy: 0.7215\n",
            "Epoch 272/600\n",
            "16342/16342 [==============================] - 11s 703us/sample - loss: 0.6578 - categorical_accuracy: 0.7172 - val_loss: 0.6288 - val_categorical_accuracy: 0.7190\n",
            "Epoch 273/600\n",
            "16342/16342 [==============================] - 11s 701us/sample - loss: 0.6572 - categorical_accuracy: 0.7154 - val_loss: 0.6253 - val_categorical_accuracy: 0.7264\n",
            "Epoch 274/600\n",
            "16342/16342 [==============================] - 11s 700us/sample - loss: 0.6592 - categorical_accuracy: 0.7151 - val_loss: 0.6267 - val_categorical_accuracy: 0.7254\n",
            "Epoch 275/600\n",
            "16342/16342 [==============================] - 11s 700us/sample - loss: 0.6612 - categorical_accuracy: 0.7135 - val_loss: 0.6446 - val_categorical_accuracy: 0.7205\n",
            "Epoch 276/600\n",
            "16342/16342 [==============================] - 11s 702us/sample - loss: 0.6571 - categorical_accuracy: 0.7133 - val_loss: 0.6258 - val_categorical_accuracy: 0.7342\n",
            "Epoch 277/600\n",
            "16342/16342 [==============================] - 11s 699us/sample - loss: 0.6566 - categorical_accuracy: 0.7147 - val_loss: 0.6299 - val_categorical_accuracy: 0.7239\n",
            "Epoch 278/600\n",
            "16342/16342 [==============================] - 11s 698us/sample - loss: 0.6572 - categorical_accuracy: 0.7167 - val_loss: 0.6256 - val_categorical_accuracy: 0.7313\n",
            "Epoch 279/600\n",
            "16342/16342 [==============================] - 11s 700us/sample - loss: 0.6574 - categorical_accuracy: 0.7140 - val_loss: 0.6270 - val_categorical_accuracy: 0.7303\n",
            "Epoch 280/600\n",
            "16342/16342 [==============================] - 11s 701us/sample - loss: 0.6551 - categorical_accuracy: 0.7181 - val_loss: 0.6318 - val_categorical_accuracy: 0.7215\n",
            "Epoch 281/600\n",
            "16342/16342 [==============================] - 11s 702us/sample - loss: 0.6628 - categorical_accuracy: 0.7117 - val_loss: 0.6318 - val_categorical_accuracy: 0.7166\n",
            "Epoch 282/600\n",
            "16342/16342 [==============================] - 11s 699us/sample - loss: 0.6595 - categorical_accuracy: 0.7117 - val_loss: 0.6271 - val_categorical_accuracy: 0.7205\n",
            "Epoch 283/600\n",
            "16342/16342 [==============================] - 11s 701us/sample - loss: 0.6570 - categorical_accuracy: 0.7162 - val_loss: 0.6428 - val_categorical_accuracy: 0.7083\n",
            "Epoch 284/600\n",
            "16342/16342 [==============================] - 11s 703us/sample - loss: 0.6632 - categorical_accuracy: 0.7103 - val_loss: 0.6290 - val_categorical_accuracy: 0.7176\n",
            "Epoch 285/600\n",
            "16342/16342 [==============================] - 11s 699us/sample - loss: 0.6600 - categorical_accuracy: 0.7129 - val_loss: 0.6332 - val_categorical_accuracy: 0.7254\n",
            "Epoch 286/600\n",
            "16342/16342 [==============================] - 11s 698us/sample - loss: 0.6578 - categorical_accuracy: 0.7133 - val_loss: 0.6243 - val_categorical_accuracy: 0.7293\n",
            "Epoch 287/600\n",
            "16342/16342 [==============================] - 11s 698us/sample - loss: 0.6569 - categorical_accuracy: 0.7150 - val_loss: 0.6465 - val_categorical_accuracy: 0.7078\n",
            "Epoch 288/600\n",
            "16342/16342 [==============================] - 11s 703us/sample - loss: 0.6587 - categorical_accuracy: 0.7149 - val_loss: 0.6280 - val_categorical_accuracy: 0.7308\n",
            "Epoch 289/600\n",
            "16342/16342 [==============================] - 11s 702us/sample - loss: 0.6573 - categorical_accuracy: 0.7163 - val_loss: 0.6288 - val_categorical_accuracy: 0.7200\n",
            "Epoch 290/600\n",
            "16342/16342 [==============================] - 11s 699us/sample - loss: 0.6551 - categorical_accuracy: 0.7165 - val_loss: 0.6294 - val_categorical_accuracy: 0.7327\n",
            "Epoch 291/600\n",
            "16342/16342 [==============================] - 11s 699us/sample - loss: 0.6565 - categorical_accuracy: 0.7156 - val_loss: 0.6238 - val_categorical_accuracy: 0.7323\n",
            "Epoch 292/600\n",
            "16342/16342 [==============================] - 11s 703us/sample - loss: 0.6559 - categorical_accuracy: 0.7145 - val_loss: 0.6271 - val_categorical_accuracy: 0.7342\n",
            "Epoch 293/600\n",
            "16342/16342 [==============================] - 11s 699us/sample - loss: 0.6604 - categorical_accuracy: 0.7146 - val_loss: 0.6235 - val_categorical_accuracy: 0.7279\n",
            "Epoch 294/600\n",
            "16342/16342 [==============================] - 11s 698us/sample - loss: 0.6550 - categorical_accuracy: 0.7165 - val_loss: 0.6240 - val_categorical_accuracy: 0.7327\n",
            "Epoch 295/600\n",
            "16342/16342 [==============================] - 11s 698us/sample - loss: 0.6566 - categorical_accuracy: 0.7192 - val_loss: 0.6265 - val_categorical_accuracy: 0.7293\n",
            "Epoch 296/600\n",
            "16342/16342 [==============================] - 11s 698us/sample - loss: 0.6548 - categorical_accuracy: 0.7160 - val_loss: 0.6264 - val_categorical_accuracy: 0.7220\n",
            "Epoch 297/600\n",
            "16342/16342 [==============================] - 11s 700us/sample - loss: 0.6541 - categorical_accuracy: 0.7170 - val_loss: 0.6344 - val_categorical_accuracy: 0.7171\n",
            "Epoch 298/600\n",
            "16342/16342 [==============================] - 11s 703us/sample - loss: 0.6586 - categorical_accuracy: 0.7122 - val_loss: 0.6287 - val_categorical_accuracy: 0.7298\n",
            "Epoch 299/600\n",
            "16342/16342 [==============================] - 11s 699us/sample - loss: 0.6525 - categorical_accuracy: 0.7175 - val_loss: 0.6244 - val_categorical_accuracy: 0.7293\n",
            "Epoch 300/600\n",
            "16342/16342 [==============================] - 11s 699us/sample - loss: 0.6532 - categorical_accuracy: 0.7180 - val_loss: 0.6229 - val_categorical_accuracy: 0.7298\n",
            "Epoch 301/600\n",
            "16342/16342 [==============================] - 11s 699us/sample - loss: 0.6576 - categorical_accuracy: 0.7139 - val_loss: 0.6227 - val_categorical_accuracy: 0.7347\n",
            "Epoch 302/600\n",
            "16342/16342 [==============================] - 11s 703us/sample - loss: 0.6567 - categorical_accuracy: 0.7146 - val_loss: 0.6265 - val_categorical_accuracy: 0.7200\n",
            "Epoch 303/600\n",
            "16342/16342 [==============================] - 11s 700us/sample - loss: 0.6528 - categorical_accuracy: 0.7197 - val_loss: 0.6247 - val_categorical_accuracy: 0.7308\n",
            "Epoch 304/600\n",
            "16342/16342 [==============================] - 11s 698us/sample - loss: 0.6608 - categorical_accuracy: 0.7110 - val_loss: 0.6364 - val_categorical_accuracy: 0.7093\n",
            "Epoch 305/600\n",
            "16342/16342 [==============================] - 11s 700us/sample - loss: 0.6561 - categorical_accuracy: 0.7169 - val_loss: 0.6251 - val_categorical_accuracy: 0.7274\n",
            "Epoch 306/600\n",
            "16342/16342 [==============================] - 11s 703us/sample - loss: 0.6587 - categorical_accuracy: 0.7118 - val_loss: 0.6334 - val_categorical_accuracy: 0.7127\n",
            "Epoch 307/600\n",
            "16342/16342 [==============================] - 11s 701us/sample - loss: 0.6571 - categorical_accuracy: 0.7133 - val_loss: 0.6245 - val_categorical_accuracy: 0.7239\n",
            "Epoch 308/600\n",
            "16342/16342 [==============================] - 11s 698us/sample - loss: 0.6554 - categorical_accuracy: 0.7160 - val_loss: 0.6268 - val_categorical_accuracy: 0.7239\n",
            "Epoch 309/600\n",
            "16342/16342 [==============================] - 11s 698us/sample - loss: 0.6577 - categorical_accuracy: 0.7133 - val_loss: 0.6242 - val_categorical_accuracy: 0.7308\n",
            "Epoch 310/600\n",
            "16342/16342 [==============================] - 11s 702us/sample - loss: 0.6584 - categorical_accuracy: 0.7163 - val_loss: 0.6244 - val_categorical_accuracy: 0.7210\n",
            "Epoch 311/600\n",
            "16342/16342 [==============================] - 11s 700us/sample - loss: 0.6559 - categorical_accuracy: 0.7169 - val_loss: 0.6237 - val_categorical_accuracy: 0.7264\n",
            "Epoch 312/600\n",
            "16342/16342 [==============================] - 11s 700us/sample - loss: 0.6555 - categorical_accuracy: 0.7143 - val_loss: 0.6383 - val_categorical_accuracy: 0.7156\n",
            "Epoch 313/600\n",
            "16342/16342 [==============================] - 11s 697us/sample - loss: 0.6586 - categorical_accuracy: 0.7136 - val_loss: 0.6245 - val_categorical_accuracy: 0.7269\n",
            "Epoch 314/600\n",
            "16342/16342 [==============================] - 11s 697us/sample - loss: 0.6568 - categorical_accuracy: 0.7170 - val_loss: 0.6230 - val_categorical_accuracy: 0.7327\n",
            "Epoch 315/600\n",
            "16342/16342 [==============================] - 11s 701us/sample - loss: 0.6554 - categorical_accuracy: 0.7166 - val_loss: 0.6238 - val_categorical_accuracy: 0.7293\n",
            "Epoch 316/600\n",
            "16342/16342 [==============================] - 11s 700us/sample - loss: 0.6613 - categorical_accuracy: 0.7118 - val_loss: 0.6227 - val_categorical_accuracy: 0.7283\n",
            "Epoch 317/600\n",
            "16342/16342 [==============================] - 11s 700us/sample - loss: 0.6549 - categorical_accuracy: 0.7167 - val_loss: 0.6245 - val_categorical_accuracy: 0.7318\n",
            "Epoch 318/600\n",
            "16342/16342 [==============================] - 11s 700us/sample - loss: 0.6569 - categorical_accuracy: 0.7133 - val_loss: 0.6297 - val_categorical_accuracy: 0.7210\n",
            "Epoch 319/600\n",
            "16342/16342 [==============================] - 11s 700us/sample - loss: 0.6586 - categorical_accuracy: 0.7136 - val_loss: 0.6286 - val_categorical_accuracy: 0.7200\n",
            "Epoch 320/600\n",
            "16342/16342 [==============================] - 11s 703us/sample - loss: 0.6603 - categorical_accuracy: 0.7116 - val_loss: 0.6239 - val_categorical_accuracy: 0.7234\n",
            "Epoch 321/600\n",
            "16342/16342 [==============================] - 11s 699us/sample - loss: 0.6570 - categorical_accuracy: 0.7157 - val_loss: 0.6271 - val_categorical_accuracy: 0.7205\n",
            "Epoch 322/600\n",
            "16342/16342 [==============================] - 11s 699us/sample - loss: 0.6544 - categorical_accuracy: 0.7166 - val_loss: 0.6313 - val_categorical_accuracy: 0.7220\n",
            "Epoch 323/600\n",
            "16342/16342 [==============================] - 11s 699us/sample - loss: 0.6596 - categorical_accuracy: 0.7153 - val_loss: 0.6238 - val_categorical_accuracy: 0.7234\n",
            "Epoch 324/600\n",
            "16342/16342 [==============================] - 11s 702us/sample - loss: 0.6548 - categorical_accuracy: 0.7174 - val_loss: 0.6260 - val_categorical_accuracy: 0.7342\n",
            "Epoch 325/600\n",
            "16342/16342 [==============================] - 11s 701us/sample - loss: 0.6566 - categorical_accuracy: 0.7148 - val_loss: 0.6239 - val_categorical_accuracy: 0.7283\n",
            "Epoch 326/600\n",
            "16342/16342 [==============================] - 11s 700us/sample - loss: 0.6609 - categorical_accuracy: 0.7129 - val_loss: 0.6262 - val_categorical_accuracy: 0.7244\n",
            "Epoch 327/600\n",
            "16342/16342 [==============================] - 11s 703us/sample - loss: 0.6561 - categorical_accuracy: 0.7163 - val_loss: 0.6246 - val_categorical_accuracy: 0.7239\n",
            "Epoch 328/600\n",
            "16342/16342 [==============================] - 11s 698us/sample - loss: 0.6565 - categorical_accuracy: 0.7170 - val_loss: 0.6265 - val_categorical_accuracy: 0.7195\n",
            "Epoch 329/600\n",
            "16342/16342 [==============================] - 11s 699us/sample - loss: 0.6558 - categorical_accuracy: 0.7144 - val_loss: 0.6243 - val_categorical_accuracy: 0.7288\n",
            "Epoch 330/600\n",
            "16342/16342 [==============================] - 11s 699us/sample - loss: 0.6557 - categorical_accuracy: 0.7178 - val_loss: 0.6236 - val_categorical_accuracy: 0.7308\n",
            "Epoch 331/600\n",
            "16342/16342 [==============================] - 11s 696us/sample - loss: 0.6552 - categorical_accuracy: 0.7154 - val_loss: 0.6232 - val_categorical_accuracy: 0.7323\n",
            "Epoch 332/600\n",
            "16342/16342 [==============================] - 11s 700us/sample - loss: 0.6559 - categorical_accuracy: 0.7160 - val_loss: 0.6267 - val_categorical_accuracy: 0.7254\n",
            "Epoch 333/600\n",
            "16342/16342 [==============================] - 11s 701us/sample - loss: 0.6587 - categorical_accuracy: 0.7165 - val_loss: 0.6453 - val_categorical_accuracy: 0.7186\n",
            "Epoch 334/600\n",
            "16342/16342 [==============================] - 11s 700us/sample - loss: 0.6544 - categorical_accuracy: 0.7194 - val_loss: 0.6283 - val_categorical_accuracy: 0.7239\n",
            "Epoch 335/600\n",
            "16342/16342 [==============================] - 11s 698us/sample - loss: 0.6564 - categorical_accuracy: 0.7163 - val_loss: 0.6254 - val_categorical_accuracy: 0.7283\n",
            "Epoch 336/600\n",
            "16342/16342 [==============================] - 11s 698us/sample - loss: 0.6569 - categorical_accuracy: 0.7162 - val_loss: 0.6299 - val_categorical_accuracy: 0.7225\n",
            "Epoch 337/600\n",
            "16342/16342 [==============================] - 11s 698us/sample - loss: 0.6576 - categorical_accuracy: 0.7155 - val_loss: 0.6237 - val_categorical_accuracy: 0.7293\n",
            "Epoch 338/600\n",
            "16342/16342 [==============================] - 11s 699us/sample - loss: 0.6565 - categorical_accuracy: 0.7169 - val_loss: 0.6292 - val_categorical_accuracy: 0.7249\n",
            "Epoch 339/600\n",
            "16342/16342 [==============================] - 11s 699us/sample - loss: 0.6565 - categorical_accuracy: 0.7142 - val_loss: 0.6271 - val_categorical_accuracy: 0.7210\n",
            "Epoch 340/600\n",
            "16342/16342 [==============================] - 12s 704us/sample - loss: 0.6558 - categorical_accuracy: 0.7161 - val_loss: 0.6282 - val_categorical_accuracy: 0.7279\n",
            "Epoch 341/600\n",
            "16342/16342 [==============================] - 11s 699us/sample - loss: 0.6545 - categorical_accuracy: 0.7193 - val_loss: 0.6275 - val_categorical_accuracy: 0.7264\n",
            "Epoch 342/600\n",
            "16342/16342 [==============================] - 11s 699us/sample - loss: 0.6558 - categorical_accuracy: 0.7163 - val_loss: 0.6252 - val_categorical_accuracy: 0.7249\n",
            "Epoch 343/600\n",
            "16342/16342 [==============================] - 11s 699us/sample - loss: 0.6568 - categorical_accuracy: 0.7157 - val_loss: 0.6251 - val_categorical_accuracy: 0.7372\n",
            "Epoch 344/600\n",
            "16342/16342 [==============================] - 11s 704us/sample - loss: 0.6597 - categorical_accuracy: 0.7162 - val_loss: 0.6421 - val_categorical_accuracy: 0.7107\n",
            "Epoch 345/600\n",
            "16342/16342 [==============================] - 11s 698us/sample - loss: 0.6586 - categorical_accuracy: 0.7153 - val_loss: 0.6237 - val_categorical_accuracy: 0.7337\n",
            "Epoch 346/600\n",
            "16342/16342 [==============================] - 11s 699us/sample - loss: 0.6559 - categorical_accuracy: 0.7184 - val_loss: 0.6254 - val_categorical_accuracy: 0.7239\n",
            "Epoch 347/600\n",
            "16342/16342 [==============================] - 11s 700us/sample - loss: 0.6561 - categorical_accuracy: 0.7122 - val_loss: 0.6310 - val_categorical_accuracy: 0.7323\n",
            "Epoch 348/600\n",
            "16342/16342 [==============================] - 11s 703us/sample - loss: 0.6609 - categorical_accuracy: 0.7134 - val_loss: 0.6231 - val_categorical_accuracy: 0.7303\n",
            "Epoch 349/600\n",
            "16342/16342 [==============================] - 11s 700us/sample - loss: 0.6542 - categorical_accuracy: 0.7141 - val_loss: 0.6367 - val_categorical_accuracy: 0.7137\n",
            "Epoch 350/600\n",
            "16342/16342 [==============================] - 11s 699us/sample - loss: 0.6550 - categorical_accuracy: 0.7174 - val_loss: 0.6330 - val_categorical_accuracy: 0.7151\n",
            "Epoch 351/600\n",
            "16342/16342 [==============================] - 11s 701us/sample - loss: 0.6534 - categorical_accuracy: 0.7169 - val_loss: 0.6270 - val_categorical_accuracy: 0.7362\n",
            "Epoch 352/600\n",
            "16342/16342 [==============================] - 11s 701us/sample - loss: 0.6572 - categorical_accuracy: 0.7159 - val_loss: 0.6370 - val_categorical_accuracy: 0.7112\n",
            "Epoch 353/600\n",
            "16342/16342 [==============================] - 11s 701us/sample - loss: 0.6586 - categorical_accuracy: 0.7139 - val_loss: 0.6272 - val_categorical_accuracy: 0.7342\n",
            "Epoch 354/600\n",
            "16342/16342 [==============================] - 11s 699us/sample - loss: 0.6553 - categorical_accuracy: 0.7170 - val_loss: 0.6281 - val_categorical_accuracy: 0.7249\n",
            "Epoch 355/600\n",
            "16342/16342 [==============================] - 11s 703us/sample - loss: 0.6569 - categorical_accuracy: 0.7139 - val_loss: 0.6243 - val_categorical_accuracy: 0.7323\n",
            "Epoch 356/600\n",
            "16342/16342 [==============================] - 11s 699us/sample - loss: 0.6587 - categorical_accuracy: 0.7142 - val_loss: 0.6246 - val_categorical_accuracy: 0.7264\n",
            "Epoch 357/600\n",
            "16342/16342 [==============================] - 11s 700us/sample - loss: 0.6559 - categorical_accuracy: 0.7157 - val_loss: 0.6254 - val_categorical_accuracy: 0.7200\n",
            "Epoch 358/600\n",
            "16342/16342 [==============================] - 11s 701us/sample - loss: 0.6538 - categorical_accuracy: 0.7178 - val_loss: 0.6228 - val_categorical_accuracy: 0.7347\n",
            "Epoch 359/600\n",
            "16342/16342 [==============================] - 11s 702us/sample - loss: 0.6560 - categorical_accuracy: 0.7181 - val_loss: 0.6232 - val_categorical_accuracy: 0.7259\n",
            "Epoch 360/600\n",
            "16342/16342 [==============================] - 11s 699us/sample - loss: 0.6584 - categorical_accuracy: 0.7158 - val_loss: 0.6272 - val_categorical_accuracy: 0.7190\n",
            "Epoch 361/600\n",
            "16342/16342 [==============================] - 11s 702us/sample - loss: 0.6554 - categorical_accuracy: 0.7170 - val_loss: 0.6262 - val_categorical_accuracy: 0.7259\n",
            "Epoch 362/600\n",
            "16342/16342 [==============================] - 11s 702us/sample - loss: 0.6538 - categorical_accuracy: 0.7173 - val_loss: 0.6228 - val_categorical_accuracy: 0.7303\n",
            "Epoch 363/600\n",
            "16342/16342 [==============================] - 11s 702us/sample - loss: 0.6528 - categorical_accuracy: 0.7201 - val_loss: 0.6255 - val_categorical_accuracy: 0.7318\n",
            "Epoch 364/600\n",
            "16342/16342 [==============================] - 11s 702us/sample - loss: 0.6550 - categorical_accuracy: 0.7161 - val_loss: 0.6283 - val_categorical_accuracy: 0.7230\n",
            "Epoch 365/600\n",
            "16342/16342 [==============================] - 11s 699us/sample - loss: 0.6584 - categorical_accuracy: 0.7134 - val_loss: 0.6259 - val_categorical_accuracy: 0.7230\n",
            "Epoch 366/600\n",
            "16342/16342 [==============================] - 11s 701us/sample - loss: 0.6563 - categorical_accuracy: 0.7153 - val_loss: 0.6305 - val_categorical_accuracy: 0.7308\n",
            "Epoch 367/600\n",
            "16342/16342 [==============================] - 11s 703us/sample - loss: 0.6562 - categorical_accuracy: 0.7190 - val_loss: 0.6310 - val_categorical_accuracy: 0.7220\n",
            "Epoch 368/600\n",
            "16342/16342 [==============================] - 11s 700us/sample - loss: 0.6586 - categorical_accuracy: 0.7111 - val_loss: 0.6312 - val_categorical_accuracy: 0.7200\n",
            "Epoch 369/600\n",
            "16342/16342 [==============================] - 11s 699us/sample - loss: 0.6546 - categorical_accuracy: 0.7159 - val_loss: 0.6241 - val_categorical_accuracy: 0.7303\n",
            "Epoch 370/600\n",
            "16342/16342 [==============================] - 12s 704us/sample - loss: 0.6533 - categorical_accuracy: 0.7178 - val_loss: 0.6282 - val_categorical_accuracy: 0.7234\n",
            "Epoch 371/600\n",
            "16342/16342 [==============================] - 11s 699us/sample - loss: 0.6581 - categorical_accuracy: 0.7150 - val_loss: 0.6359 - val_categorical_accuracy: 0.7122\n",
            "Epoch 372/600\n",
            "16342/16342 [==============================] - 11s 700us/sample - loss: 0.6557 - categorical_accuracy: 0.7166 - val_loss: 0.6232 - val_categorical_accuracy: 0.7249\n",
            "Epoch 373/600\n",
            "16342/16342 [==============================] - 11s 703us/sample - loss: 0.6544 - categorical_accuracy: 0.7168 - val_loss: 0.6250 - val_categorical_accuracy: 0.7293\n",
            "Epoch 374/600\n",
            "16342/16342 [==============================] - 11s 700us/sample - loss: 0.6528 - categorical_accuracy: 0.7180 - val_loss: 0.6236 - val_categorical_accuracy: 0.7303\n",
            "Epoch 375/600\n",
            "16342/16342 [==============================] - 11s 700us/sample - loss: 0.6550 - categorical_accuracy: 0.7170 - val_loss: 0.6273 - val_categorical_accuracy: 0.7264\n",
            "Epoch 376/600\n",
            "16342/16342 [==============================] - 11s 701us/sample - loss: 0.6540 - categorical_accuracy: 0.7172 - val_loss: 0.6369 - val_categorical_accuracy: 0.7137\n",
            "Epoch 377/600\n",
            "16342/16342 [==============================] - 11s 701us/sample - loss: 0.6544 - categorical_accuracy: 0.7161 - val_loss: 0.6293 - val_categorical_accuracy: 0.7220\n",
            "Epoch 378/600\n",
            "16342/16342 [==============================] - 11s 702us/sample - loss: 0.6543 - categorical_accuracy: 0.7161 - val_loss: 0.6236 - val_categorical_accuracy: 0.7303\n",
            "Epoch 379/600\n",
            "16342/16342 [==============================] - 11s 700us/sample - loss: 0.6558 - categorical_accuracy: 0.7164 - val_loss: 0.6277 - val_categorical_accuracy: 0.7303\n",
            "Epoch 380/600\n",
            "16342/16342 [==============================] - 11s 701us/sample - loss: 0.6567 - categorical_accuracy: 0.7141 - val_loss: 0.6248 - val_categorical_accuracy: 0.7249\n",
            "Epoch 381/600\n",
            "16342/16342 [==============================] - 11s 701us/sample - loss: 0.6569 - categorical_accuracy: 0.7154 - val_loss: 0.6467 - val_categorical_accuracy: 0.7190\n",
            "Epoch 382/600\n",
            "16342/16342 [==============================] - 11s 701us/sample - loss: 0.6606 - categorical_accuracy: 0.7131 - val_loss: 0.6317 - val_categorical_accuracy: 0.7195\n",
            "Epoch 383/600\n",
            "16342/16342 [==============================] - 11s 700us/sample - loss: 0.6541 - categorical_accuracy: 0.7169 - val_loss: 0.6231 - val_categorical_accuracy: 0.7381\n",
            "Epoch 384/600\n",
            "16342/16342 [==============================] - 11s 701us/sample - loss: 0.6572 - categorical_accuracy: 0.7148 - val_loss: 0.6287 - val_categorical_accuracy: 0.7254\n",
            "Epoch 385/600\n",
            "16342/16342 [==============================] - 11s 702us/sample - loss: 0.6558 - categorical_accuracy: 0.7140 - val_loss: 0.6340 - val_categorical_accuracy: 0.7112\n",
            "Epoch 386/600\n",
            "16342/16342 [==============================] - 11s 698us/sample - loss: 0.6557 - categorical_accuracy: 0.7147 - val_loss: 0.6216 - val_categorical_accuracy: 0.7327\n",
            "Epoch 387/600\n",
            "16342/16342 [==============================] - 11s 699us/sample - loss: 0.6542 - categorical_accuracy: 0.7164 - val_loss: 0.6219 - val_categorical_accuracy: 0.7293\n",
            "Epoch 388/600\n",
            "16342/16342 [==============================] - 11s 699us/sample - loss: 0.6574 - categorical_accuracy: 0.7134 - val_loss: 0.6248 - val_categorical_accuracy: 0.7337\n",
            "Epoch 389/600\n",
            "16342/16342 [==============================] - 11s 698us/sample - loss: 0.6516 - categorical_accuracy: 0.7196 - val_loss: 0.6314 - val_categorical_accuracy: 0.7220\n",
            "Epoch 390/600\n",
            "16342/16342 [==============================] - 11s 700us/sample - loss: 0.6539 - categorical_accuracy: 0.7161 - val_loss: 0.6218 - val_categorical_accuracy: 0.7308\n",
            "Epoch 391/600\n",
            "16342/16342 [==============================] - 11s 703us/sample - loss: 0.6547 - categorical_accuracy: 0.7153 - val_loss: 0.6255 - val_categorical_accuracy: 0.7225\n",
            "Epoch 392/600\n",
            "16342/16342 [==============================] - 11s 702us/sample - loss: 0.6535 - categorical_accuracy: 0.7188 - val_loss: 0.6222 - val_categorical_accuracy: 0.7303\n",
            "Epoch 393/600\n",
            "16342/16342 [==============================] - 11s 701us/sample - loss: 0.6568 - categorical_accuracy: 0.7158 - val_loss: 0.6269 - val_categorical_accuracy: 0.7225\n",
            "Epoch 394/600\n",
            "16342/16342 [==============================] - 11s 701us/sample - loss: 0.6525 - categorical_accuracy: 0.7156 - val_loss: 0.6301 - val_categorical_accuracy: 0.7195\n",
            "Epoch 395/600\n",
            "16342/16342 [==============================] - 11s 699us/sample - loss: 0.6538 - categorical_accuracy: 0.7162 - val_loss: 0.6214 - val_categorical_accuracy: 0.7342\n",
            "Epoch 396/600\n",
            "16342/16342 [==============================] - 11s 699us/sample - loss: 0.6547 - categorical_accuracy: 0.7174 - val_loss: 0.6214 - val_categorical_accuracy: 0.7332\n",
            "Epoch 397/600\n",
            "16342/16342 [==============================] - 11s 703us/sample - loss: 0.6515 - categorical_accuracy: 0.7193 - val_loss: 0.6217 - val_categorical_accuracy: 0.7303\n",
            "Epoch 398/600\n",
            "16342/16342 [==============================] - 11s 701us/sample - loss: 0.6552 - categorical_accuracy: 0.7179 - val_loss: 0.6510 - val_categorical_accuracy: 0.7166\n",
            "Epoch 399/600\n",
            "16342/16342 [==============================] - 11s 700us/sample - loss: 0.6535 - categorical_accuracy: 0.7145 - val_loss: 0.6218 - val_categorical_accuracy: 0.7298\n",
            "Epoch 400/600\n",
            "16342/16342 [==============================] - 12s 704us/sample - loss: 0.6523 - categorical_accuracy: 0.7164 - val_loss: 0.6334 - val_categorical_accuracy: 0.7186\n",
            "Epoch 401/600\n",
            "16342/16342 [==============================] - 11s 702us/sample - loss: 0.6537 - categorical_accuracy: 0.7147 - val_loss: 0.6220 - val_categorical_accuracy: 0.7298\n",
            "Epoch 402/600\n",
            "16342/16342 [==============================] - 12s 704us/sample - loss: 0.6530 - categorical_accuracy: 0.7161 - val_loss: 0.6287 - val_categorical_accuracy: 0.7200\n",
            "Epoch 403/600\n",
            "16342/16342 [==============================] - 11s 700us/sample - loss: 0.6512 - categorical_accuracy: 0.7167 - val_loss: 0.6195 - val_categorical_accuracy: 0.7332\n",
            "Epoch 404/600\n",
            "16342/16342 [==============================] - 11s 703us/sample - loss: 0.6528 - categorical_accuracy: 0.7174 - val_loss: 0.6263 - val_categorical_accuracy: 0.7244\n",
            "Epoch 405/600\n",
            "16342/16342 [==============================] - 11s 699us/sample - loss: 0.6591 - categorical_accuracy: 0.7156 - val_loss: 0.6214 - val_categorical_accuracy: 0.7274\n",
            "Epoch 406/600\n",
            "16342/16342 [==============================] - 11s 700us/sample - loss: 0.6500 - categorical_accuracy: 0.7207 - val_loss: 0.6218 - val_categorical_accuracy: 0.7332\n",
            "Epoch 407/600\n",
            "16342/16342 [==============================] - 11s 703us/sample - loss: 0.6492 - categorical_accuracy: 0.7196 - val_loss: 0.6221 - val_categorical_accuracy: 0.7244\n",
            "Epoch 408/600\n",
            "16342/16342 [==============================] - 11s 700us/sample - loss: 0.6483 - categorical_accuracy: 0.7202 - val_loss: 0.6319 - val_categorical_accuracy: 0.7293\n",
            "Epoch 409/600\n",
            "16342/16342 [==============================] - 11s 699us/sample - loss: 0.6502 - categorical_accuracy: 0.7175 - val_loss: 0.6188 - val_categorical_accuracy: 0.7288\n",
            "Epoch 410/600\n",
            "16342/16342 [==============================] - 11s 698us/sample - loss: 0.6478 - categorical_accuracy: 0.7206 - val_loss: 0.6289 - val_categorical_accuracy: 0.7195\n",
            "Epoch 411/600\n",
            "16342/16342 [==============================] - 11s 698us/sample - loss: 0.6500 - categorical_accuracy: 0.7169 - val_loss: 0.6188 - val_categorical_accuracy: 0.7274\n",
            "Epoch 412/600\n",
            "16342/16342 [==============================] - 11s 699us/sample - loss: 0.6536 - categorical_accuracy: 0.7130 - val_loss: 0.6186 - val_categorical_accuracy: 0.7283\n",
            "Epoch 413/600\n",
            "16342/16342 [==============================] - 11s 700us/sample - loss: 0.6451 - categorical_accuracy: 0.7196 - val_loss: 0.6219 - val_categorical_accuracy: 0.7234\n",
            "Epoch 414/600\n",
            "16342/16342 [==============================] - 11s 702us/sample - loss: 0.6507 - categorical_accuracy: 0.7175 - val_loss: 0.6175 - val_categorical_accuracy: 0.7288\n",
            "Epoch 415/600\n",
            "16342/16342 [==============================] - 11s 699us/sample - loss: 0.6510 - categorical_accuracy: 0.7140 - val_loss: 0.6179 - val_categorical_accuracy: 0.7269\n",
            "Epoch 416/600\n",
            "16342/16342 [==============================] - 11s 698us/sample - loss: 0.6498 - categorical_accuracy: 0.7176 - val_loss: 0.6205 - val_categorical_accuracy: 0.7283\n",
            "Epoch 417/600\n",
            "16342/16342 [==============================] - 11s 697us/sample - loss: 0.6474 - categorical_accuracy: 0.7192 - val_loss: 0.6177 - val_categorical_accuracy: 0.7288\n",
            "Epoch 418/600\n",
            "16342/16342 [==============================] - 11s 699us/sample - loss: 0.6486 - categorical_accuracy: 0.7161 - val_loss: 0.6189 - val_categorical_accuracy: 0.7308\n",
            "Epoch 419/600\n",
            "16342/16342 [==============================] - 11s 696us/sample - loss: 0.6502 - categorical_accuracy: 0.7138 - val_loss: 0.6180 - val_categorical_accuracy: 0.7249\n",
            "Epoch 420/600\n",
            "16342/16342 [==============================] - 11s 698us/sample - loss: 0.6467 - categorical_accuracy: 0.7180 - val_loss: 0.6196 - val_categorical_accuracy: 0.7337\n",
            "Epoch 421/600\n",
            "16342/16342 [==============================] - 11s 701us/sample - loss: 0.6483 - categorical_accuracy: 0.7172 - val_loss: 0.6162 - val_categorical_accuracy: 0.7288\n",
            "Epoch 422/600\n",
            "16342/16342 [==============================] - 11s 701us/sample - loss: 0.6446 - categorical_accuracy: 0.7204 - val_loss: 0.6171 - val_categorical_accuracy: 0.7283\n",
            "Epoch 423/600\n",
            "16342/16342 [==============================] - 11s 701us/sample - loss: 0.6471 - categorical_accuracy: 0.7166 - val_loss: 0.6529 - val_categorical_accuracy: 0.7048\n",
            "Epoch 424/600\n",
            "16342/16342 [==============================] - 11s 698us/sample - loss: 0.6486 - categorical_accuracy: 0.7168 - val_loss: 0.6217 - val_categorical_accuracy: 0.7234\n",
            "Epoch 425/600\n",
            "16342/16342 [==============================] - 12s 704us/sample - loss: 0.6449 - categorical_accuracy: 0.7195 - val_loss: 0.6197 - val_categorical_accuracy: 0.7259\n",
            "Epoch 426/600\n",
            "16342/16342 [==============================] - 11s 699us/sample - loss: 0.6492 - categorical_accuracy: 0.7160 - val_loss: 0.6165 - val_categorical_accuracy: 0.7293\n",
            "Epoch 427/600\n",
            "16342/16342 [==============================] - 11s 701us/sample - loss: 0.6470 - categorical_accuracy: 0.7202 - val_loss: 0.6186 - val_categorical_accuracy: 0.7259\n",
            "Epoch 428/600\n",
            "16342/16342 [==============================] - 11s 704us/sample - loss: 0.6452 - categorical_accuracy: 0.7177 - val_loss: 0.6251 - val_categorical_accuracy: 0.7254\n",
            "Epoch 429/600\n",
            "16342/16342 [==============================] - 11s 700us/sample - loss: 0.6471 - categorical_accuracy: 0.7192 - val_loss: 0.6182 - val_categorical_accuracy: 0.7318\n",
            "Epoch 430/600\n",
            "16342/16342 [==============================] - 11s 700us/sample - loss: 0.6433 - categorical_accuracy: 0.7209 - val_loss: 0.6284 - val_categorical_accuracy: 0.7195\n",
            "Epoch 431/600\n",
            "16342/16342 [==============================] - 12s 704us/sample - loss: 0.6454 - categorical_accuracy: 0.7191 - val_loss: 0.6167 - val_categorical_accuracy: 0.7303\n",
            "Epoch 432/600\n",
            "16342/16342 [==============================] - 11s 699us/sample - loss: 0.6519 - categorical_accuracy: 0.7121 - val_loss: 0.6214 - val_categorical_accuracy: 0.7239\n",
            "Epoch 433/600\n",
            "16342/16342 [==============================] - 11s 699us/sample - loss: 0.6459 - categorical_accuracy: 0.7174 - val_loss: 0.6187 - val_categorical_accuracy: 0.7283\n",
            "Epoch 434/600\n",
            "16342/16342 [==============================] - 11s 704us/sample - loss: 0.6475 - categorical_accuracy: 0.7186 - val_loss: 0.6229 - val_categorical_accuracy: 0.7239\n",
            "Epoch 435/600\n",
            "16342/16342 [==============================] - 11s 701us/sample - loss: 0.6437 - categorical_accuracy: 0.7205 - val_loss: 0.6225 - val_categorical_accuracy: 0.7279\n",
            "Epoch 436/600\n",
            "16342/16342 [==============================] - 12s 705us/sample - loss: 0.6467 - categorical_accuracy: 0.7180 - val_loss: 0.6234 - val_categorical_accuracy: 0.7259\n",
            "Epoch 437/600\n",
            "16342/16342 [==============================] - 11s 701us/sample - loss: 0.6452 - categorical_accuracy: 0.7200 - val_loss: 0.6222 - val_categorical_accuracy: 0.7220\n",
            "Epoch 438/600\n",
            "16342/16342 [==============================] - 12s 705us/sample - loss: 0.6456 - categorical_accuracy: 0.7171 - val_loss: 0.6178 - val_categorical_accuracy: 0.7332\n",
            "Epoch 439/600\n",
            "16342/16342 [==============================] - 11s 700us/sample - loss: 0.6448 - categorical_accuracy: 0.7180 - val_loss: 0.6169 - val_categorical_accuracy: 0.7298\n",
            "Epoch 440/600\n",
            "16342/16342 [==============================] - 11s 701us/sample - loss: 0.6477 - categorical_accuracy: 0.7174 - val_loss: 0.6398 - val_categorical_accuracy: 0.7166\n",
            "Epoch 441/600\n",
            "16342/16342 [==============================] - 11s 703us/sample - loss: 0.6476 - categorical_accuracy: 0.7180 - val_loss: 0.6163 - val_categorical_accuracy: 0.7303\n",
            "Epoch 442/600\n",
            "16342/16342 [==============================] - 11s 703us/sample - loss: 0.6453 - categorical_accuracy: 0.7169 - val_loss: 0.6264 - val_categorical_accuracy: 0.7230\n",
            "Epoch 443/600\n",
            "16342/16342 [==============================] - 11s 701us/sample - loss: 0.6428 - categorical_accuracy: 0.7192 - val_loss: 0.6144 - val_categorical_accuracy: 0.7283\n",
            "Epoch 444/600\n",
            "16342/16342 [==============================] - 11s 700us/sample - loss: 0.6428 - categorical_accuracy: 0.7209 - val_loss: 0.6248 - val_categorical_accuracy: 0.7323\n",
            "Epoch 445/600\n",
            "16342/16342 [==============================] - 11s 700us/sample - loss: 0.6463 - categorical_accuracy: 0.7190 - val_loss: 0.6180 - val_categorical_accuracy: 0.7279\n",
            "Epoch 446/600\n",
            "16342/16342 [==============================] - 11s 697us/sample - loss: 0.6440 - categorical_accuracy: 0.7194 - val_loss: 0.6163 - val_categorical_accuracy: 0.7313\n",
            "Epoch 447/600\n",
            "16342/16342 [==============================] - 11s 700us/sample - loss: 0.6498 - categorical_accuracy: 0.7159 - val_loss: 0.6366 - val_categorical_accuracy: 0.7156\n",
            "Epoch 448/600\n",
            "16342/16342 [==============================] - 11s 704us/sample - loss: 0.6432 - categorical_accuracy: 0.7221 - val_loss: 0.6205 - val_categorical_accuracy: 0.7259\n",
            "Epoch 449/600\n",
            "16342/16342 [==============================] - 11s 700us/sample - loss: 0.6425 - categorical_accuracy: 0.7205 - val_loss: 0.6174 - val_categorical_accuracy: 0.7279\n",
            "Epoch 450/600\n",
            "16342/16342 [==============================] - 11s 699us/sample - loss: 0.6487 - categorical_accuracy: 0.7168 - val_loss: 0.6162 - val_categorical_accuracy: 0.7283\n",
            "Epoch 451/600\n",
            "16342/16342 [==============================] - 11s 703us/sample - loss: 0.6424 - categorical_accuracy: 0.7218 - val_loss: 0.6145 - val_categorical_accuracy: 0.7332\n",
            "Epoch 452/600\n",
            "16342/16342 [==============================] - 11s 699us/sample - loss: 0.6444 - categorical_accuracy: 0.7194 - val_loss: 0.6189 - val_categorical_accuracy: 0.7288\n",
            "Epoch 453/600\n",
            "16342/16342 [==============================] - 11s 699us/sample - loss: 0.6427 - categorical_accuracy: 0.7234 - val_loss: 0.6272 - val_categorical_accuracy: 0.7249\n",
            "Epoch 454/600\n",
            "16342/16342 [==============================] - 11s 700us/sample - loss: 0.6427 - categorical_accuracy: 0.7199 - val_loss: 0.6189 - val_categorical_accuracy: 0.7293\n",
            "Epoch 455/600\n",
            "16342/16342 [==============================] - 11s 702us/sample - loss: 0.6466 - categorical_accuracy: 0.7167 - val_loss: 0.6180 - val_categorical_accuracy: 0.7274\n",
            "Epoch 456/600\n",
            "16342/16342 [==============================] - 11s 701us/sample - loss: 0.6456 - categorical_accuracy: 0.7183 - val_loss: 0.6155 - val_categorical_accuracy: 0.7293\n",
            "Epoch 457/600\n",
            "16342/16342 [==============================] - 11s 702us/sample - loss: 0.6449 - categorical_accuracy: 0.7202 - val_loss: 0.6222 - val_categorical_accuracy: 0.7264\n",
            "Epoch 458/600\n",
            "16342/16342 [==============================] - 11s 700us/sample - loss: 0.6441 - categorical_accuracy: 0.7213 - val_loss: 0.6285 - val_categorical_accuracy: 0.7171\n",
            "Epoch 459/600\n",
            "16342/16342 [==============================] - 11s 700us/sample - loss: 0.6475 - categorical_accuracy: 0.7151 - val_loss: 0.6182 - val_categorical_accuracy: 0.7264\n",
            "Epoch 460/600\n",
            "16342/16342 [==============================] - 11s 700us/sample - loss: 0.6466 - categorical_accuracy: 0.7178 - val_loss: 0.6197 - val_categorical_accuracy: 0.7259\n",
            "Epoch 461/600\n",
            "16342/16342 [==============================] - 11s 704us/sample - loss: 0.6469 - categorical_accuracy: 0.7167 - val_loss: 0.6175 - val_categorical_accuracy: 0.7264\n",
            "Epoch 462/600\n",
            "16342/16342 [==============================] - 11s 700us/sample - loss: 0.6408 - categorical_accuracy: 0.7219 - val_loss: 0.6146 - val_categorical_accuracy: 0.7303\n",
            "Epoch 463/600\n",
            "16342/16342 [==============================] - 11s 699us/sample - loss: 0.6426 - categorical_accuracy: 0.7198 - val_loss: 0.6206 - val_categorical_accuracy: 0.7264\n",
            "Epoch 464/600\n",
            "16342/16342 [==============================] - 11s 703us/sample - loss: 0.6481 - categorical_accuracy: 0.7153 - val_loss: 0.6256 - val_categorical_accuracy: 0.7244\n",
            "Epoch 465/600\n",
            "16342/16342 [==============================] - 11s 697us/sample - loss: 0.6448 - categorical_accuracy: 0.7211 - val_loss: 0.6163 - val_categorical_accuracy: 0.7283\n",
            "Epoch 466/600\n",
            "16342/16342 [==============================] - 11s 701us/sample - loss: 0.6433 - categorical_accuracy: 0.7193 - val_loss: 0.6156 - val_categorical_accuracy: 0.7283\n",
            "Epoch 467/600\n",
            "16342/16342 [==============================] - 11s 698us/sample - loss: 0.6442 - categorical_accuracy: 0.7197 - val_loss: 0.6308 - val_categorical_accuracy: 0.7200\n",
            "Epoch 468/600\n",
            "16342/16342 [==============================] - 11s 697us/sample - loss: 0.6445 - categorical_accuracy: 0.7181 - val_loss: 0.6230 - val_categorical_accuracy: 0.7283\n",
            "Epoch 469/600\n",
            "16342/16342 [==============================] - 11s 700us/sample - loss: 0.6402 - categorical_accuracy: 0.7208 - val_loss: 0.6141 - val_categorical_accuracy: 0.7298\n",
            "Epoch 470/600\n",
            "16342/16342 [==============================] - 11s 700us/sample - loss: 0.6425 - categorical_accuracy: 0.7237 - val_loss: 0.6173 - val_categorical_accuracy: 0.7303\n",
            "Epoch 471/600\n",
            "16342/16342 [==============================] - 11s 701us/sample - loss: 0.6434 - categorical_accuracy: 0.7213 - val_loss: 0.6136 - val_categorical_accuracy: 0.7323\n",
            "Epoch 472/600\n",
            "16342/16342 [==============================] - 11s 699us/sample - loss: 0.6422 - categorical_accuracy: 0.7202 - val_loss: 0.6254 - val_categorical_accuracy: 0.7210\n",
            "Epoch 473/600\n",
            "16342/16342 [==============================] - 11s 699us/sample - loss: 0.6434 - categorical_accuracy: 0.7196 - val_loss: 0.6130 - val_categorical_accuracy: 0.7308\n",
            "Epoch 474/600\n",
            "16342/16342 [==============================] - 11s 701us/sample - loss: 0.6433 - categorical_accuracy: 0.7207 - val_loss: 0.6297 - val_categorical_accuracy: 0.7283\n",
            "Epoch 475/600\n",
            "16342/16342 [==============================] - 11s 702us/sample - loss: 0.6459 - categorical_accuracy: 0.7186 - val_loss: 0.6234 - val_categorical_accuracy: 0.7254\n",
            "Epoch 476/600\n",
            "16342/16342 [==============================] - 11s 700us/sample - loss: 0.6397 - categorical_accuracy: 0.7207 - val_loss: 0.6200 - val_categorical_accuracy: 0.7376\n",
            "Epoch 477/600\n",
            "16342/16342 [==============================] - 11s 700us/sample - loss: 0.6406 - categorical_accuracy: 0.7241 - val_loss: 0.6130 - val_categorical_accuracy: 0.7308\n",
            "Epoch 478/600\n",
            "16342/16342 [==============================] - 11s 703us/sample - loss: 0.6396 - categorical_accuracy: 0.7227 - val_loss: 0.6159 - val_categorical_accuracy: 0.7274\n",
            "Epoch 479/600\n",
            "16342/16342 [==============================] - 11s 702us/sample - loss: 0.6432 - categorical_accuracy: 0.7217 - val_loss: 0.6161 - val_categorical_accuracy: 0.7293\n",
            "Epoch 480/600\n",
            "16342/16342 [==============================] - 11s 700us/sample - loss: 0.6425 - categorical_accuracy: 0.7202 - val_loss: 0.6146 - val_categorical_accuracy: 0.7303\n",
            "Epoch 481/600\n",
            "16342/16342 [==============================] - 11s 702us/sample - loss: 0.6422 - categorical_accuracy: 0.7219 - val_loss: 0.6135 - val_categorical_accuracy: 0.7283\n",
            "Epoch 482/600\n",
            "16342/16342 [==============================] - 11s 700us/sample - loss: 0.6402 - categorical_accuracy: 0.7235 - val_loss: 0.6149 - val_categorical_accuracy: 0.7323\n",
            "Epoch 483/600\n",
            "16342/16342 [==============================] - 11s 698us/sample - loss: 0.6452 - categorical_accuracy: 0.7183 - val_loss: 0.6155 - val_categorical_accuracy: 0.7259\n",
            "Epoch 484/600\n",
            "16342/16342 [==============================] - 11s 700us/sample - loss: 0.6429 - categorical_accuracy: 0.7211 - val_loss: 0.6122 - val_categorical_accuracy: 0.7298\n",
            "Epoch 485/600\n",
            "16342/16342 [==============================] - 11s 703us/sample - loss: 0.6399 - categorical_accuracy: 0.7226 - val_loss: 0.6165 - val_categorical_accuracy: 0.7332\n",
            "Epoch 486/600\n",
            "16342/16342 [==============================] - 11s 700us/sample - loss: 0.6404 - categorical_accuracy: 0.7213 - val_loss: 0.6138 - val_categorical_accuracy: 0.7318\n",
            "Epoch 487/600\n",
            "16342/16342 [==============================] - 11s 698us/sample - loss: 0.6417 - categorical_accuracy: 0.7201 - val_loss: 0.6134 - val_categorical_accuracy: 0.7318\n",
            "Epoch 488/600\n",
            "16342/16342 [==============================] - 11s 699us/sample - loss: 0.6421 - categorical_accuracy: 0.7210 - val_loss: 0.6127 - val_categorical_accuracy: 0.7337\n",
            "Epoch 489/600\n",
            "16342/16342 [==============================] - 11s 701us/sample - loss: 0.6405 - categorical_accuracy: 0.7225 - val_loss: 0.6123 - val_categorical_accuracy: 0.7327\n",
            "Epoch 490/600\n",
            "16342/16342 [==============================] - 11s 701us/sample - loss: 0.6380 - categorical_accuracy: 0.7229 - val_loss: 0.6135 - val_categorical_accuracy: 0.7288\n",
            "Epoch 491/600\n",
            "16342/16342 [==============================] - 11s 703us/sample - loss: 0.6386 - categorical_accuracy: 0.7234 - val_loss: 0.6135 - val_categorical_accuracy: 0.7318\n",
            "Epoch 492/600\n",
            "16342/16342 [==============================] - 11s 702us/sample - loss: 0.6384 - categorical_accuracy: 0.7264 - val_loss: 0.6137 - val_categorical_accuracy: 0.7308\n",
            "Epoch 493/600\n",
            "16342/16342 [==============================] - 11s 699us/sample - loss: 0.6413 - categorical_accuracy: 0.7213 - val_loss: 0.6130 - val_categorical_accuracy: 0.7303\n",
            "Epoch 494/600\n",
            "16342/16342 [==============================] - 11s 699us/sample - loss: 0.6428 - categorical_accuracy: 0.7202 - val_loss: 0.6149 - val_categorical_accuracy: 0.7288\n",
            "Epoch 495/600\n",
            "16342/16342 [==============================] - 11s 698us/sample - loss: 0.6381 - categorical_accuracy: 0.7234 - val_loss: 0.6115 - val_categorical_accuracy: 0.7308\n",
            "Epoch 496/600\n",
            "16342/16342 [==============================] - 11s 702us/sample - loss: 0.6395 - categorical_accuracy: 0.7251 - val_loss: 0.6200 - val_categorical_accuracy: 0.7244\n",
            "Epoch 497/600\n",
            "16342/16342 [==============================] - 11s 700us/sample - loss: 0.6386 - categorical_accuracy: 0.7218 - val_loss: 0.6256 - val_categorical_accuracy: 0.7327\n",
            "Epoch 498/600\n",
            "16342/16342 [==============================] - 11s 698us/sample - loss: 0.6399 - categorical_accuracy: 0.7223 - val_loss: 0.6192 - val_categorical_accuracy: 0.7239\n",
            "Epoch 499/600\n",
            "16342/16342 [==============================] - 11s 700us/sample - loss: 0.6368 - categorical_accuracy: 0.7243 - val_loss: 0.6155 - val_categorical_accuracy: 0.7274\n",
            "Epoch 500/600\n",
            "16342/16342 [==============================] - 11s 703us/sample - loss: 0.6396 - categorical_accuracy: 0.7210 - val_loss: 0.6113 - val_categorical_accuracy: 0.7269\n",
            "Epoch 501/600\n",
            "16342/16342 [==============================] - 11s 700us/sample - loss: 0.6395 - categorical_accuracy: 0.7206 - val_loss: 0.6131 - val_categorical_accuracy: 0.7293\n",
            "Epoch 502/600\n",
            "16342/16342 [==============================] - 11s 698us/sample - loss: 0.6416 - categorical_accuracy: 0.7216 - val_loss: 0.6220 - val_categorical_accuracy: 0.7254\n",
            "Epoch 503/600\n",
            "16342/16342 [==============================] - 11s 700us/sample - loss: 0.6406 - categorical_accuracy: 0.7211 - val_loss: 0.6181 - val_categorical_accuracy: 0.7264\n",
            "Epoch 504/600\n",
            "16342/16342 [==============================] - 11s 703us/sample - loss: 0.6429 - categorical_accuracy: 0.7210 - val_loss: 0.6138 - val_categorical_accuracy: 0.7279\n",
            "Epoch 505/600\n",
            "16342/16342 [==============================] - 11s 701us/sample - loss: 0.6389 - categorical_accuracy: 0.7234 - val_loss: 0.6125 - val_categorical_accuracy: 0.7303\n",
            "Epoch 506/600\n",
            "16342/16342 [==============================] - 11s 698us/sample - loss: 0.6407 - categorical_accuracy: 0.7225 - val_loss: 0.6200 - val_categorical_accuracy: 0.7205\n",
            "Epoch 507/600\n",
            "16342/16342 [==============================] - 11s 701us/sample - loss: 0.6375 - categorical_accuracy: 0.7248 - val_loss: 0.6240 - val_categorical_accuracy: 0.7176\n",
            "Epoch 508/600\n",
            "16342/16342 [==============================] - 11s 701us/sample - loss: 0.6391 - categorical_accuracy: 0.7212 - val_loss: 0.6151 - val_categorical_accuracy: 0.7249\n",
            "Epoch 509/600\n",
            "16342/16342 [==============================] - 11s 699us/sample - loss: 0.6420 - categorical_accuracy: 0.7208 - val_loss: 0.6111 - val_categorical_accuracy: 0.7337\n",
            "Epoch 510/600\n",
            "16342/16342 [==============================] - 11s 700us/sample - loss: 0.6417 - categorical_accuracy: 0.7202 - val_loss: 0.6109 - val_categorical_accuracy: 0.7308\n",
            "Epoch 511/600\n",
            "16342/16342 [==============================] - 11s 703us/sample - loss: 0.6423 - categorical_accuracy: 0.7218 - val_loss: 0.6116 - val_categorical_accuracy: 0.7283\n",
            "Epoch 512/600\n",
            "16342/16342 [==============================] - 11s 700us/sample - loss: 0.6383 - categorical_accuracy: 0.7263 - val_loss: 0.6107 - val_categorical_accuracy: 0.7298\n",
            "Epoch 513/600\n",
            "16342/16342 [==============================] - 11s 698us/sample - loss: 0.6386 - categorical_accuracy: 0.7245 - val_loss: 0.6137 - val_categorical_accuracy: 0.7337\n",
            "Epoch 514/600\n",
            "16342/16342 [==============================] - 11s 699us/sample - loss: 0.6376 - categorical_accuracy: 0.7248 - val_loss: 0.6103 - val_categorical_accuracy: 0.7308\n",
            "Epoch 515/600\n",
            "16342/16342 [==============================] - 11s 703us/sample - loss: 0.6388 - categorical_accuracy: 0.7217 - val_loss: 0.6101 - val_categorical_accuracy: 0.7313\n",
            "Epoch 516/600\n",
            "16342/16342 [==============================] - 11s 701us/sample - loss: 0.6381 - categorical_accuracy: 0.7236 - val_loss: 0.6099 - val_categorical_accuracy: 0.7298\n",
            "Epoch 517/600\n",
            "16342/16342 [==============================] - 11s 699us/sample - loss: 0.6429 - categorical_accuracy: 0.7178 - val_loss: 0.6123 - val_categorical_accuracy: 0.7352\n",
            "Epoch 518/600\n",
            "16342/16342 [==============================] - 11s 703us/sample - loss: 0.6373 - categorical_accuracy: 0.7259 - val_loss: 0.6117 - val_categorical_accuracy: 0.7288\n",
            "Epoch 519/600\n",
            "16342/16342 [==============================] - 11s 699us/sample - loss: 0.6365 - categorical_accuracy: 0.7253 - val_loss: 0.6097 - val_categorical_accuracy: 0.7269\n",
            "Epoch 520/600\n",
            "16342/16342 [==============================] - 11s 698us/sample - loss: 0.6384 - categorical_accuracy: 0.7228 - val_loss: 0.6204 - val_categorical_accuracy: 0.7195\n",
            "Epoch 521/600\n",
            "16342/16342 [==============================] - 11s 699us/sample - loss: 0.6396 - categorical_accuracy: 0.7229 - val_loss: 0.6117 - val_categorical_accuracy: 0.7279\n",
            "Epoch 522/600\n",
            "16342/16342 [==============================] - 11s 699us/sample - loss: 0.6403 - categorical_accuracy: 0.7205 - val_loss: 0.6166 - val_categorical_accuracy: 0.7234\n",
            "Epoch 523/600\n",
            "16342/16342 [==============================] - 11s 703us/sample - loss: 0.6371 - categorical_accuracy: 0.7237 - val_loss: 0.6091 - val_categorical_accuracy: 0.7327\n",
            "Epoch 524/600\n",
            "16342/16342 [==============================] - 11s 701us/sample - loss: 0.6362 - categorical_accuracy: 0.7225 - val_loss: 0.6123 - val_categorical_accuracy: 0.7279\n",
            "Epoch 525/600\n",
            "16342/16342 [==============================] - 11s 698us/sample - loss: 0.6366 - categorical_accuracy: 0.7231 - val_loss: 0.6151 - val_categorical_accuracy: 0.7332\n",
            "Epoch 526/600\n",
            "16342/16342 [==============================] - 12s 704us/sample - loss: 0.6406 - categorical_accuracy: 0.7197 - val_loss: 0.6087 - val_categorical_accuracy: 0.7283\n",
            "Epoch 527/600\n",
            "16342/16342 [==============================] - 11s 701us/sample - loss: 0.6370 - categorical_accuracy: 0.7231 - val_loss: 0.6176 - val_categorical_accuracy: 0.7264\n",
            "Epoch 528/600\n",
            "16342/16342 [==============================] - 11s 697us/sample - loss: 0.6369 - categorical_accuracy: 0.7244 - val_loss: 0.6355 - val_categorical_accuracy: 0.7210\n",
            "Epoch 529/600\n",
            "16342/16342 [==============================] - 11s 698us/sample - loss: 0.6422 - categorical_accuracy: 0.7195 - val_loss: 0.6078 - val_categorical_accuracy: 0.7323\n",
            "Epoch 530/600\n",
            "16342/16342 [==============================] - 11s 699us/sample - loss: 0.6353 - categorical_accuracy: 0.7238 - val_loss: 0.6090 - val_categorical_accuracy: 0.7313\n",
            "Epoch 531/600\n",
            "16342/16342 [==============================] - 11s 698us/sample - loss: 0.6367 - categorical_accuracy: 0.7234 - val_loss: 0.6166 - val_categorical_accuracy: 0.7244\n",
            "Epoch 532/600\n",
            "16342/16342 [==============================] - 11s 701us/sample - loss: 0.6444 - categorical_accuracy: 0.7140 - val_loss: 0.6170 - val_categorical_accuracy: 0.7347\n",
            "Epoch 533/600\n",
            "16342/16342 [==============================] - 11s 702us/sample - loss: 0.6375 - categorical_accuracy: 0.7234 - val_loss: 0.6097 - val_categorical_accuracy: 0.7288\n",
            "Epoch 534/600\n",
            "16342/16342 [==============================] - 11s 698us/sample - loss: 0.6356 - categorical_accuracy: 0.7220 - val_loss: 0.6146 - val_categorical_accuracy: 0.7215\n",
            "Epoch 535/600\n",
            "16342/16342 [==============================] - 11s 698us/sample - loss: 0.6377 - categorical_accuracy: 0.7229 - val_loss: 0.6089 - val_categorical_accuracy: 0.7298\n",
            "Epoch 536/600\n",
            "16342/16342 [==============================] - 11s 699us/sample - loss: 0.6357 - categorical_accuracy: 0.7248 - val_loss: 0.6198 - val_categorical_accuracy: 0.7249\n",
            "Epoch 537/600\n",
            "16342/16342 [==============================] - 11s 700us/sample - loss: 0.6388 - categorical_accuracy: 0.7189 - val_loss: 0.6070 - val_categorical_accuracy: 0.7288\n",
            "Epoch 538/600\n",
            "16342/16342 [==============================] - 11s 701us/sample - loss: 0.6396 - categorical_accuracy: 0.7217 - val_loss: 0.6128 - val_categorical_accuracy: 0.7376\n",
            "Epoch 539/600\n",
            "16342/16342 [==============================] - 11s 700us/sample - loss: 0.6354 - categorical_accuracy: 0.7232 - val_loss: 0.6080 - val_categorical_accuracy: 0.7308\n",
            "Epoch 540/600\n",
            "16342/16342 [==============================] - 11s 699us/sample - loss: 0.6377 - categorical_accuracy: 0.7220 - val_loss: 0.6065 - val_categorical_accuracy: 0.7283\n",
            "Epoch 541/600\n",
            "16342/16342 [==============================] - 11s 704us/sample - loss: 0.6394 - categorical_accuracy: 0.7214 - val_loss: 0.6123 - val_categorical_accuracy: 0.7254\n",
            "Epoch 542/600\n",
            "16342/16342 [==============================] - 11s 698us/sample - loss: 0.6366 - categorical_accuracy: 0.7204 - val_loss: 0.6223 - val_categorical_accuracy: 0.7327\n",
            "Epoch 543/600\n",
            "16342/16342 [==============================] - 11s 699us/sample - loss: 0.6394 - categorical_accuracy: 0.7230 - val_loss: 0.6111 - val_categorical_accuracy: 0.7249\n",
            "Epoch 544/600\n",
            "16342/16342 [==============================] - 11s 698us/sample - loss: 0.6324 - categorical_accuracy: 0.7254 - val_loss: 0.6072 - val_categorical_accuracy: 0.7303\n",
            "Epoch 545/600\n",
            "16342/16342 [==============================] - 11s 704us/sample - loss: 0.6380 - categorical_accuracy: 0.7215 - val_loss: 0.6105 - val_categorical_accuracy: 0.7249\n",
            "Epoch 546/600\n",
            "16342/16342 [==============================] - 11s 699us/sample - loss: 0.6376 - categorical_accuracy: 0.7218 - val_loss: 0.6059 - val_categorical_accuracy: 0.7327\n",
            "Epoch 547/600\n",
            "16342/16342 [==============================] - 11s 700us/sample - loss: 0.6333 - categorical_accuracy: 0.7260 - val_loss: 0.6107 - val_categorical_accuracy: 0.7357\n",
            "Epoch 548/600\n",
            "16342/16342 [==============================] - 11s 698us/sample - loss: 0.6319 - categorical_accuracy: 0.7259 - val_loss: 0.6060 - val_categorical_accuracy: 0.7342\n",
            "Epoch 549/600\n",
            "16342/16342 [==============================] - 11s 700us/sample - loss: 0.6352 - categorical_accuracy: 0.7229 - val_loss: 0.6027 - val_categorical_accuracy: 0.7347\n",
            "Epoch 550/600\n",
            "16342/16342 [==============================] - 12s 704us/sample - loss: 0.6330 - categorical_accuracy: 0.7259 - val_loss: 0.6044 - val_categorical_accuracy: 0.7298\n",
            "Epoch 551/600\n",
            "16342/16342 [==============================] - 11s 700us/sample - loss: 0.6348 - categorical_accuracy: 0.7263 - val_loss: 0.6159 - val_categorical_accuracy: 0.7352\n",
            "Epoch 552/600\n",
            "16342/16342 [==============================] - 11s 698us/sample - loss: 0.6330 - categorical_accuracy: 0.7235 - val_loss: 0.6221 - val_categorical_accuracy: 0.7181\n",
            "Epoch 553/600\n",
            "16342/16342 [==============================] - 11s 703us/sample - loss: 0.6341 - categorical_accuracy: 0.7246 - val_loss: 0.6116 - val_categorical_accuracy: 0.7342\n",
            "Epoch 554/600\n",
            "16342/16342 [==============================] - 11s 701us/sample - loss: 0.6344 - categorical_accuracy: 0.7225 - val_loss: 0.6613 - val_categorical_accuracy: 0.6926\n",
            "Epoch 555/600\n",
            "16342/16342 [==============================] - 11s 697us/sample - loss: 0.6365 - categorical_accuracy: 0.7233 - val_loss: 0.6049 - val_categorical_accuracy: 0.7323\n",
            "Epoch 556/600\n",
            "16342/16342 [==============================] - 11s 700us/sample - loss: 0.6311 - categorical_accuracy: 0.7262 - val_loss: 0.6154 - val_categorical_accuracy: 0.7254\n",
            "Epoch 557/600\n",
            "16342/16342 [==============================] - 11s 698us/sample - loss: 0.6332 - categorical_accuracy: 0.7251 - val_loss: 0.6086 - val_categorical_accuracy: 0.7416\n",
            "Epoch 558/600\n",
            "16342/16342 [==============================] - 11s 702us/sample - loss: 0.6337 - categorical_accuracy: 0.7253 - val_loss: 0.6001 - val_categorical_accuracy: 0.7323\n",
            "Epoch 559/600\n",
            "16342/16342 [==============================] - 11s 700us/sample - loss: 0.6316 - categorical_accuracy: 0.7246 - val_loss: 0.6023 - val_categorical_accuracy: 0.7332\n",
            "Epoch 560/600\n",
            "16342/16342 [==============================] - 11s 698us/sample - loss: 0.6305 - categorical_accuracy: 0.7271 - val_loss: 0.5999 - val_categorical_accuracy: 0.7337\n",
            "Epoch 561/600\n",
            "16342/16342 [==============================] - 11s 697us/sample - loss: 0.6321 - categorical_accuracy: 0.7254 - val_loss: 0.5982 - val_categorical_accuracy: 0.7313\n",
            "Epoch 562/600\n",
            "16342/16342 [==============================] - 11s 703us/sample - loss: 0.6322 - categorical_accuracy: 0.7246 - val_loss: 0.6021 - val_categorical_accuracy: 0.7303\n",
            "Epoch 563/600\n",
            "16342/16342 [==============================] - 11s 700us/sample - loss: 0.6302 - categorical_accuracy: 0.7251 - val_loss: 0.6040 - val_categorical_accuracy: 0.7269\n",
            "Epoch 564/600\n",
            "16342/16342 [==============================] - 11s 699us/sample - loss: 0.6289 - categorical_accuracy: 0.7272 - val_loss: 0.5972 - val_categorical_accuracy: 0.7332\n",
            "Epoch 565/600\n",
            "16342/16342 [==============================] - 11s 698us/sample - loss: 0.6317 - categorical_accuracy: 0.7257 - val_loss: 0.5972 - val_categorical_accuracy: 0.7376\n",
            "Epoch 566/600\n",
            "16342/16342 [==============================] - 11s 702us/sample - loss: 0.6327 - categorical_accuracy: 0.7243 - val_loss: 0.5960 - val_categorical_accuracy: 0.7347\n",
            "Epoch 567/600\n",
            "16342/16342 [==============================] - 11s 702us/sample - loss: 0.6298 - categorical_accuracy: 0.7284 - val_loss: 0.6007 - val_categorical_accuracy: 0.7381\n",
            "Epoch 568/600\n",
            "16342/16342 [==============================] - 11s 698us/sample - loss: 0.6289 - categorical_accuracy: 0.7291 - val_loss: 0.5984 - val_categorical_accuracy: 0.7406\n",
            "Epoch 569/600\n",
            "16342/16342 [==============================] - 11s 698us/sample - loss: 0.6288 - categorical_accuracy: 0.7271 - val_loss: 0.5956 - val_categorical_accuracy: 0.7362\n",
            "Epoch 570/600\n",
            "16342/16342 [==============================] - 11s 698us/sample - loss: 0.6278 - categorical_accuracy: 0.7290 - val_loss: 0.6049 - val_categorical_accuracy: 0.7230\n",
            "Epoch 571/600\n",
            "16342/16342 [==============================] - 11s 698us/sample - loss: 0.6298 - categorical_accuracy: 0.7278 - val_loss: 0.5981 - val_categorical_accuracy: 0.7357\n",
            "Epoch 572/600\n",
            "16342/16342 [==============================] - 11s 698us/sample - loss: 0.6270 - categorical_accuracy: 0.7294 - val_loss: 0.6158 - val_categorical_accuracy: 0.7259\n",
            "Epoch 573/600\n",
            "16342/16342 [==============================] - 11s 696us/sample - loss: 0.6289 - categorical_accuracy: 0.7245 - val_loss: 0.5960 - val_categorical_accuracy: 0.7460\n",
            "Epoch 574/600\n",
            "16342/16342 [==============================] - 11s 698us/sample - loss: 0.6282 - categorical_accuracy: 0.7269 - val_loss: 0.6043 - val_categorical_accuracy: 0.7416\n",
            "Epoch 575/600\n",
            "16342/16342 [==============================] - 11s 699us/sample - loss: 0.6272 - categorical_accuracy: 0.7290 - val_loss: 0.6178 - val_categorical_accuracy: 0.7210\n",
            "Epoch 576/600\n",
            "16342/16342 [==============================] - 11s 698us/sample - loss: 0.6278 - categorical_accuracy: 0.7276 - val_loss: 0.5931 - val_categorical_accuracy: 0.7440\n",
            "Epoch 577/600\n",
            "16342/16342 [==============================] - 12s 704us/sample - loss: 0.6271 - categorical_accuracy: 0.7270 - val_loss: 0.5938 - val_categorical_accuracy: 0.7376\n",
            "Epoch 578/600\n",
            "16342/16342 [==============================] - 11s 699us/sample - loss: 0.6238 - categorical_accuracy: 0.7314 - val_loss: 0.5923 - val_categorical_accuracy: 0.7420\n",
            "Epoch 579/600\n",
            "16342/16342 [==============================] - 11s 698us/sample - loss: 0.6256 - categorical_accuracy: 0.7292 - val_loss: 0.5997 - val_categorical_accuracy: 0.7425\n",
            "Epoch 580/600\n",
            "16342/16342 [==============================] - 11s 699us/sample - loss: 0.6255 - categorical_accuracy: 0.7308 - val_loss: 0.5918 - val_categorical_accuracy: 0.7396\n",
            "Epoch 581/600\n",
            "16342/16342 [==============================] - 11s 700us/sample - loss: 0.6262 - categorical_accuracy: 0.7285 - val_loss: 0.5969 - val_categorical_accuracy: 0.7347\n",
            "Epoch 582/600\n",
            "16342/16342 [==============================] - 11s 699us/sample - loss: 0.6260 - categorical_accuracy: 0.7298 - val_loss: 0.5922 - val_categorical_accuracy: 0.7381\n",
            "Epoch 583/600\n",
            "16342/16342 [==============================] - 11s 702us/sample - loss: 0.6237 - categorical_accuracy: 0.7328 - val_loss: 0.5894 - val_categorical_accuracy: 0.7445\n",
            "Epoch 584/600\n",
            "16342/16342 [==============================] - 11s 698us/sample - loss: 0.6265 - categorical_accuracy: 0.7263 - val_loss: 0.5888 - val_categorical_accuracy: 0.7411\n",
            "Epoch 585/600\n",
            "16342/16342 [==============================] - 11s 698us/sample - loss: 0.6227 - categorical_accuracy: 0.7339 - val_loss: 0.5963 - val_categorical_accuracy: 0.7376\n",
            "Epoch 586/600\n",
            "16342/16342 [==============================] - 11s 698us/sample - loss: 0.6221 - categorical_accuracy: 0.7324 - val_loss: 0.5953 - val_categorical_accuracy: 0.7332\n",
            "Epoch 587/600\n",
            "16342/16342 [==============================] - 11s 699us/sample - loss: 0.6230 - categorical_accuracy: 0.7307 - val_loss: 0.5879 - val_categorical_accuracy: 0.7406\n",
            "Epoch 588/600\n",
            "16342/16342 [==============================] - 11s 700us/sample - loss: 0.6219 - categorical_accuracy: 0.7320 - val_loss: 0.6025 - val_categorical_accuracy: 0.7264\n",
            "Epoch 589/600\n",
            "16342/16342 [==============================] - 11s 703us/sample - loss: 0.6269 - categorical_accuracy: 0.7301 - val_loss: 0.5907 - val_categorical_accuracy: 0.7391\n",
            "Epoch 590/600\n",
            "16342/16342 [==============================] - 11s 699us/sample - loss: 0.6218 - categorical_accuracy: 0.7320 - val_loss: 0.5884 - val_categorical_accuracy: 0.7386\n",
            "Epoch 591/600\n",
            "16342/16342 [==============================] - 11s 697us/sample - loss: 0.6226 - categorical_accuracy: 0.7293 - val_loss: 0.5866 - val_categorical_accuracy: 0.7416\n",
            "Epoch 592/600\n",
            "16342/16342 [==============================] - 11s 698us/sample - loss: 0.6202 - categorical_accuracy: 0.7308 - val_loss: 0.5905 - val_categorical_accuracy: 0.7450\n",
            "Epoch 593/600\n",
            "16342/16342 [==============================] - 11s 701us/sample - loss: 0.6197 - categorical_accuracy: 0.7323 - val_loss: 0.6263 - val_categorical_accuracy: 0.7156\n",
            "Epoch 594/600\n",
            "16342/16342 [==============================] - 11s 702us/sample - loss: 0.6203 - categorical_accuracy: 0.7317 - val_loss: 0.5936 - val_categorical_accuracy: 0.7337\n",
            "Epoch 595/600\n",
            "16342/16342 [==============================] - 11s 698us/sample - loss: 0.6228 - categorical_accuracy: 0.7282 - val_loss: 0.5871 - val_categorical_accuracy: 0.7406\n",
            "Epoch 596/600\n",
            "16342/16342 [==============================] - 11s 699us/sample - loss: 0.6246 - categorical_accuracy: 0.7286 - val_loss: 0.6085 - val_categorical_accuracy: 0.7298\n",
            "Epoch 597/600\n",
            "16342/16342 [==============================] - 11s 699us/sample - loss: 0.6199 - categorical_accuracy: 0.7286 - val_loss: 0.5990 - val_categorical_accuracy: 0.7372\n",
            "Epoch 598/600\n",
            "16342/16342 [==============================] - 11s 703us/sample - loss: 0.6175 - categorical_accuracy: 0.7339 - val_loss: 0.5900 - val_categorical_accuracy: 0.7352\n",
            "Epoch 599/600\n",
            "16342/16342 [==============================] - 11s 700us/sample - loss: 0.6234 - categorical_accuracy: 0.7318 - val_loss: 0.5856 - val_categorical_accuracy: 0.7411\n",
            "Epoch 600/600\n",
            "16342/16342 [==============================] - 11s 698us/sample - loss: 0.6170 - categorical_accuracy: 0.7325 - val_loss: 0.5879 - val_categorical_accuracy: 0.7372\n",
            "5018.088250000001\n"
          ]
        }
      ],
      "source": [
        "import time\n",
        "start = time.clock()\n",
        "history = model.fit(x_train, t_train, batch_size=batch_size, epochs=n_epochs, verbose=1, validation_data=(x_dev, t_dev))    \n",
        "print (time.clock() - start)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 358
        },
        "colab_type": "code",
        "id": "ei8jQFBcgqQ1",
        "outputId": "82074c05-f2f7-4835-aa5d-edd3aeddc64f"
      },
      "outputs": [
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 576x360 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "output_type": "display_data"
        }
      ],
      "source": [
        "results=pd.DataFrame(history.history)\n",
        "results.plot(figsize=(8, 5))\n",
        "plt.grid(True)\n",
        "plt.xlabel (\"Epochs\")\n",
        "plt.ylabel (\"Accuracy - Mean Log Loss\")\n",
        "plt.gca().set_ylim(0, 1) # set the vertical range to [0-1]\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "ESvg7wr-slAk"
      },
      "source": [
        "Note how the learning curves are plain. BP learning algorithm converges slowly or to a poor local optimum. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 213
        },
        "colab_type": "code",
        "id": "UV5Pfxp8hAWZ",
        "outputId": "e737c579-493c-40b0-fba0-2fa7962d1b30"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{'batch_size': 500,\n",
              " 'do_validation': True,\n",
              " 'epochs': 600,\n",
              " 'metrics': ['loss',\n",
              "  'categorical_accuracy',\n",
              "  'val_loss',\n",
              "  'val_categorical_accuracy'],\n",
              " 'samples': 16342,\n",
              " 'steps': None,\n",
              " 'verbose': 0}"
            ]
          },
          "execution_count": 19,
          "metadata": {
            "tags": []
          },
          "output_type": "execute_result"
        }
      ],
      "source": [
        "history.params"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 101
        },
        "colab_type": "code",
        "id": "roAiIXx2h7Gw",
        "outputId": "fe3de481-d46e-4db0-83b6-1d9039c1cfb9"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>loss</th>\n",
              "      <th>categorical_accuracy</th>\n",
              "      <th>val_loss</th>\n",
              "      <th>val_categorical_accuracy</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>599</th>\n",
              "      <td>0.616998</td>\n",
              "      <td>0.73253</td>\n",
              "      <td>0.587924</td>\n",
              "      <td>0.737151</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "         loss  categorical_accuracy  val_loss  val_categorical_accuracy\n",
              "599  0.616998               0.73253  0.587924                  0.737151"
            ]
          },
          "execution_count": 20,
          "metadata": {
            "tags": []
          },
          "output_type": "execute_result"
        }
      ],
      "source": [
        "results[-1:]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 55
        },
        "colab_type": "code",
        "id": "PWFtUYNKqqmX",
        "outputId": "f3daaeac-fde0-4e95-dc26-8ad75acad733"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Accuracy for the training set:  0.7325296998023987\n"
          ]
        }
      ],
      "source": [
        "print (\"Accuracy for the training set: \", results.categorical_accuracy.values[-1:][0])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 55
        },
        "colab_type": "code",
        "id": "yP53JgeQqqma",
        "outputId": "a8064e6a-b2b8-4eef-bd02-c79ce5178530",
        "scrolled": true
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Accuracy for the development test set:  0.7371512651443481\n"
          ]
        }
      ],
      "source": [
        "print (\"Accuracy for the development test set: \", results.val_categorical_accuracy.values[-1:][0])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "2wtSZeG6fH_V"
      },
      "source": [
        "Now the accuracy is 73% on training and 73% on the develoment test set, worse than those achieved with just one hidden layer with 1,000 neurons. Moreover, the training process takes 83 minutes to accomplish 600 epochs, about 20,000 iterations with a batch size of 500.   "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "H5X5iQSKfTOY"
      },
      "source": [
        "Let's see how the model predicts on the development test set:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 389
        },
        "colab_type": "code",
        "id": "t3gUC7-vfgL8",
        "outputId": "9b650c36-3f65-4861-b224-d8ff95c91759"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([[0.35, 0.61, 0.05],\n",
              "       [0.  , 0.06, 0.94],\n",
              "       [0.91, 0.09, 0.  ],\n",
              "       [0.02, 0.29, 0.69],\n",
              "       [0.71, 0.26, 0.03],\n",
              "       [0.02, 0.5 , 0.47],\n",
              "       [0.01, 0.38, 0.61],\n",
              "       [0.  , 0.05, 0.95],\n",
              "       [0.  , 0.  , 1.  ],\n",
              "       [0.74, 0.24, 0.02],\n",
              "       [0.15, 0.74, 0.11],\n",
              "       [0.42, 0.51, 0.07],\n",
              "       [0.4 , 0.48, 0.12],\n",
              "       [0.33, 0.48, 0.18],\n",
              "       [0.91, 0.09, 0.  ],\n",
              "       [0.01, 0.1 , 0.9 ],\n",
              "       [0.92, 0.07, 0.  ],\n",
              "       [0.  , 0.05, 0.95],\n",
              "       [0.1 , 0.7 , 0.2 ],\n",
              "       [0.  , 0.02, 0.98]], dtype=float32)"
            ]
          },
          "execution_count": 23,
          "metadata": {
            "tags": []
          },
          "output_type": "execute_result"
        }
      ],
      "source": [
        "dev_predictions=model.predict(x_dev).round(2)\n",
        "dev_predictions[:20]\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 389
        },
        "colab_type": "code",
        "id": "JGueKhZHqqmd",
        "outputId": "e8860e58-86fc-43a5-9dea-6d4620cb58bb"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([[0., 1., 0.],\n",
              "       [0., 0., 1.],\n",
              "       [1., 0., 0.],\n",
              "       [0., 0., 1.],\n",
              "       [1., 0., 0.],\n",
              "       [0., 1., 0.],\n",
              "       [0., 0., 1.],\n",
              "       [0., 0., 1.],\n",
              "       [0., 0., 1.],\n",
              "       [1., 0., 0.],\n",
              "       [0., 1., 0.],\n",
              "       [0., 1., 0.],\n",
              "       [0., 1., 0.],\n",
              "       [0., 1., 0.],\n",
              "       [1., 0., 0.],\n",
              "       [0., 0., 1.],\n",
              "       [1., 0., 0.],\n",
              "       [0., 0., 1.],\n",
              "       [0., 1., 0.],\n",
              "       [0., 0., 1.]], dtype=float32)"
            ]
          },
          "execution_count": 24,
          "metadata": {
            "tags": []
          },
          "output_type": "execute_result"
        }
      ],
      "source": [
        "dev_rounded_predictions=np.round(dev_predictions)\n",
        "indices = np.argmax(dev_predictions,1)\n",
        "for row, index in zip(dev_rounded_predictions, indices): row[index]=1\n",
        "dev_rounded_predictions[:20]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 389
        },
        "colab_type": "code",
        "id": "vWmB9Pc-qqme",
        "outputId": "83c88f77-6459-411a-9863-6bc421d79815"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([[1., 0., 0.],\n",
              "       [0., 0., 1.],\n",
              "       [1., 0., 0.],\n",
              "       [0., 1., 0.],\n",
              "       [0., 1., 0.],\n",
              "       [0., 1., 0.],\n",
              "       [0., 0., 1.],\n",
              "       [0., 0., 1.],\n",
              "       [0., 0., 1.],\n",
              "       [0., 1., 0.],\n",
              "       [0., 1., 0.],\n",
              "       [0., 1., 0.],\n",
              "       [1., 0., 0.],\n",
              "       [0., 0., 1.],\n",
              "       [1., 0., 0.],\n",
              "       [0., 0., 1.],\n",
              "       [1., 0., 0.],\n",
              "       [0., 0., 1.],\n",
              "       [0., 1., 0.],\n",
              "       [0., 0., 1.]])"
            ]
          },
          "execution_count": 25,
          "metadata": {
            "tags": []
          },
          "output_type": "execute_result"
        }
      ],
      "source": [
        "t_dev[:20] #target classes"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 90
        },
        "colab_type": "code",
        "id": "efzEzJ5tqqmf",
        "outputId": "1267c44c-914f-4043-8cd5-705460fec52f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[False  True  True False False  True  True  True  True False  True  True\n",
            " False False  True  True  True  True  True  True  True False  True  True\n",
            "  True  True  True  True  True  True]\n"
          ]
        }
      ],
      "source": [
        "dev_correct_predictions = np.equal(np.argmax(dev_rounded_predictions,1),np.argmax(t_dev,1))\n",
        "print (dev_correct_predictions[:30])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 55
        },
        "colab_type": "code",
        "id": "w9vjCo41Zn_e",
        "outputId": "08c51584-647b-4742-eebd-f1fc155f0225"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "Counter({False: 539, True: 1504})"
            ]
          },
          "execution_count": 27,
          "metadata": {
            "tags": []
          },
          "output_type": "execute_result"
        }
      ],
      "source": [
        "from collections import Counter\n",
        "Counter (dev_correct_predictions)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "qmH4txRThl6M"
      },
      "source": [
        "Obviously, this model makes more mistakes than the one-hidden layer neural network with 1,000 neurons.   "
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [],
      "name": "5.MedianHouseValue. Tanh Deep Keras ANN.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.7"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
